{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Bacterial Growth Rate and Yield from Full Genomic Data \n",
    "\n",
    "## Danesh Moradigaravand \n",
    "### Center for Computational Biology\n",
    "### University of Birmingham \n",
    "\n",
    "***\n",
    "\n",
    "Bacterial growth is known to be determined by ecological factors, inclduing antimicrobial resistance. High throughput growth assays allow rapid parallel screening for a large number of bacterial strains in a short period of time. I comnive this capability with the wealth of information from WGS of bacterial sequences to predict the bacterial sequences. \n",
    "\n",
    "Here I will present a full implementation of a data analytics pipeline, in which bacterial growth is treated as a continious trait and genomic features are used as predictors. Three predictive models will be exaimned:\n",
    "\n",
    "**1. Base line regularized regression Model**\n",
    "\n",
    "**2. Ensemble model based on gradient boosted regression trees**\n",
    "\n",
    "**3. Residual Neural Network**\n",
    "\n",
    "These choice of these models reflect the increasing the complexity and accounting for high order interaction amonsgt input features. As for the genetic input features, I have used the output of the pan-genome recontruction pipeline, Roary, and the and the output of the resistome from the ARIBA pipeline. The model employs the Scikit-learn and Keras libraries. \n",
    "\n",
    "The pipeline comprise of following steps:\n",
    "\n",
    "**Input Reading and Feature engineering &rarr; Model Training &rarr; Inference &rarr; Prediction &rarr; Annotation and feature importance analysis**\n",
    "\n",
    "---\n",
    "## 1-Input Reading and Feature Engineering\n",
    "\n",
    "### pan-genome file manipulation\n",
    "\n",
    "The input of the algorithm is the CSV and R file output of Roary. In the first step, duplicated entries are removed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processed():\n",
    "    def __init__(self,PATH):\n",
    "        self.PATH=PATH\n",
    "        \n",
    "    def deduplication(self, Rtab,Gene_PA):\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        tmp_tab=pd.DataFrame()\n",
    "        Rtab=os.path.join(self.PATH, \"gene_presence_absence.Rtab\")\n",
    "        Gene_PA=os.path.join(self.PATH, \"gene_presence_absence.csv\")\n",
    "        \n",
    "        if not os.path.isfile( Rtab):\n",
    "            print(\"No Rtab file\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Reading Rtab file\")\n",
    "            tmp_tab= pd.read_csv( Rtab,index_col=0)\n",
    "            print(\"Rtab file is imported\")\n",
    "            \n",
    "        if not os.path.isfile(Gene_PA):\n",
    "            print(\"No accessory gene file\")\n",
    "            return\n",
    "        \n",
    "        print(\"Reading Rtab file\")\n",
    "        \n",
    "        print(\"Delete non-unique Genes activated\")\n",
    "        print(\"Accessory gene file\")\n",
    "        tmp_csv=pd.read_csv(Gene_PA, usecols = [\"Gene\",\"Non-unique Gene name\"])\n",
    "        id_un=np.where(tmp_csv[\"Non-unique Gene name\"].isnull())[0]\n",
    "        print(\"Number of genes before removing genes: %d\" % tmp_tab.shape[0])\n",
    "        tmp_tab=tmp_tab.iloc[id_un,:]\n",
    "        print(\"Number of genes after removing genes: %d\" % tmp_tab.shape[0])\n",
    "\n",
    "        print(\"\\nRemoving correlated gene clusters\")\n",
    "        print(\"Number of genes before clustering: %d\" % tmp_tab.shape[0])\n",
    "        tmp_dedup=tmp_tab.drop_duplicates()\n",
    "        print(\"Number of genes after clustering: %d\" % tmp_dedup.shape[0])\n",
    "        Gene_inp=tmp_dedup.transpose()\n",
    "        Gene_inp.to_csv(os.path.join(self.PATH, \"processed_gene_presence_absence.Rtab\"))\n",
    "\n",
    "    def join_feature_response(self,features_file, response_file, column=0, dropNA=True):\n",
    "        import os\n",
    "        import pandas as pd\n",
    "    \n",
    "        features_dataframe=pd.read_csv(os.path.join(self.PATH, features_file), index_col=0, sep=\"\\t\")\n",
    "        reponse_dataframe=pd.read_csv(os.path.join(self.PATH, response_file), index_col=0, sep=\"\\t\")\n",
    "        \n",
    "        print(\"Joining Trait:\"+reponse_dataframe.columns[column])\n",
    "        input_dataframe=reponse_dataframe[[reponse_dataframe.columns[column]]].join(features_dataframe,how='inner')\n",
    "        input_dataframe=input_dataframe.dropna(axis=0, how='any', inplace=False)\n",
    "        input_dataframe.columns.values[0]='label'\n",
    "        return(input_dataframe)\n",
    "\n",
    "    def split_train_test_save_output(self, input_dataset,postfix,label='label',save=False, test_size=0.2):\n",
    "        import os\n",
    "        import numpy as np\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split( input_dataset.drop(columns=['label']),input_dataset[['label']], test_size=test_size, random_state=1)\n",
    "        if save:\n",
    "            X_train.to_csv(os.path.join(self.PATH, 'X_train_'+postfix+'.txt'), sep=\"\\t\")\n",
    "            X_test.to_csv(os.path.join(self.PATH, 'X_test_'+postfix+'.txt'), sep=\"\\t\")\n",
    "            y_train.to_csv(os.path.join(self.PATH, 'y_train_'+postfix+'.txt'), sep=\"\\t\")\n",
    "            y_test.to_csv(os.path.join(self.PATH, 'y_test_'+postfix+'.txt'), sep=\"\\t\")\n",
    "        return(np.array(X_train), np.array(X_test), np.squeeze(np.array(y_train)), np.squeeze(np.array(y_test)))\n",
    "\n",
    "#preparation dataset \n",
    "PATH=\"/Users/moradigd/Documents/Prediction/\"\n",
    "\n",
    "response='Metadata_median_NoAB.txt'\n",
    "features='pangene.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3-Model design\n",
    "\n",
    "We employ three classes of predictive models. The baseline lasso regression, the gradient boosted regression models and residual neural networks.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted regression tree\n",
    "\n",
    "In order to opmtimize the parameters, we first create a set of grid search parameters for the gradient boosted regression model. In the next step the model will be tuned with 2-fold cross validation. Best parameters and predictions are stored.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth  min_samples_split  learning_rate loss\n",
       "0           100          2                  2           0.01   ls\n",
       "1           100          4                  2           0.01   ls\n",
       "2           200          2                  2           0.01   ls\n",
       "3           200          4                  2           0.01   ls"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "params={\n",
    "    'n_estimators':[100,200],\n",
    "    'max_depth':[2, 4],\n",
    "    'min_samples_split':[2],\n",
    "    'learning_rate':[0.01],\n",
    "    'loss':['ls']\n",
    "}\n",
    "\n",
    "def param_gridsearch_xgregressor(PATH, *params):\n",
    "    '''\n",
    "    input: PATH\n",
    "    dictionary of parameter values for gradient boosting trees\n",
    "    output: parameter file\n",
    "    '''\n",
    "\n",
    "    output_param=[]\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    for i in params[0]['n_estimators']:\n",
    "        for j in params[0]['max_depth']:\n",
    "            for k in params[0]['min_samples_split']:\n",
    "                for b in params[0]['learning_rate']:\n",
    "                    for m in params[0]['loss']:\n",
    "                        output_param.append([i,j,k,b,m])\n",
    "    df=pd.DataFrame(output_param, columns=['n_estimators','max_depth','min_samples_split','learning_rate','loss'])\n",
    "    df.to_csv(os.path.join(PATH, 'xgregressor_param.txt'), sep=\"\\t\")\n",
    "    return(df)\n",
    "\n",
    "def predictor_boostingregressor(X_train_val,y_train_val, X_test,y_test,params_matrix):\n",
    "    mse_grid=[]\n",
    "    for i in range(params_matrix.shape[0]):\n",
    "        print(i/params_matrix.shape[0])\n",
    "        params=params_matrix.iloc[i,:].to_dict()\n",
    "        print(params)    \n",
    "        rf=ensemble.GradientBoostingRegressor(**params)\n",
    "        scores = cross_validate(rf, X_train_val,y_train_val, scoring=['neg_mean_squared_error'], cv=2)\n",
    "        mse_grid.append(np.mean(scores['test_neg_mean_squared_error'])) \n",
    "        print(np.mean(scores['test_neg_mean_squared_error']))\n",
    "    \n",
    "    best_params=params_matrix.iloc[np.argmin(mse_grid),:].to_dict()\n",
    "    model = ensemble.GradientBoostingRegressor(**best_params)\n",
    "    model.fit(X_train_val,y_train_val) \n",
    "    #mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    return(best_params, model)\n",
    "\n",
    "\n",
    "PATH='/Users/moradigd/Documents/Prediction/Pan_genome'\n",
    "params_matrix_regressor=param_gridsearch_xgregressor(PATH, params)\n",
    "params_matrix_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso \n",
    "\n",
    "In order to opmtimize the parameters, we first create a set of grid search parameters for the gradient boosted regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.000000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alpha\n",
       "0  1.000000e-15\n",
       "1  1.000000e-10\n",
       "2  1.000000e-08\n",
       "3  1.000000e-05\n",
       "4  1.000000e-04\n",
       "5  1.000000e-03\n",
       "6  1.000000e-02\n",
       "7  1.000000e+00\n",
       "8  5.000000e+00\n",
       "9  1.000000e+01"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_gridsearch_lasso(PATH, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'alpha':[1e-15, 1e-10, 1e-8, 1e-5,1e-4, 1e-3,1e-2, 1, 5, 10]}\n",
    "def param_gridsearch_lasso(PATH, *params):\n",
    "    '''\n",
    "    input: PATH\n",
    "    dictionary of parameter values for lasso\n",
    "    output: parameter file\n",
    "    '''\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    output_param=[]\n",
    "    for i in params[0]['alpha']:\n",
    "        output_param.append(i)\n",
    "    df=pd.DataFrame(output_param, columns=['alpha'])\n",
    "    df.to_csv(os.path.join(PATH, 'lasso_param.txt'), sep=\"\\t\")\n",
    "    return(df)\n",
    "\n",
    "PATH='/Users/moradigd/Documents/Prediction/Pan_genome'\n",
    "params_matrix_lasso=param_gridsearch_lasso(PATH, params)\n",
    "\n",
    "def predictor_lasso(X_train_val,y_train_val, X_test,y_test,params_matrix):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    mse_grid=[]\n",
    "    for i in range(params_matrix.shape[0]):\n",
    "        print(i/params_matrix.shape[0])\n",
    "        params=params_matrix.iloc[i,:].to_dict()\n",
    "        print(params)\n",
    "        lassoreg = Lasso(normalize=True, max_iter=1e5, **params)\n",
    "        scores = cross_validate(lassoreg, X_train_val,y_train_val, scoring=['neg_mean_squared_error'], cv=2)\n",
    "        mse_grid.append(np.mean(scores['test_neg_mean_squared_error']))\n",
    "    \n",
    "    best_params=params_matrix.iloc[np.argmin(mse_grid),:].to_dict()\n",
    "    model = Lasso(normalize=True, max_iter=1e5, **best_params)\n",
    "    model.fit(X_train_val,y_train_val) \n",
    "    return(best_params, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Neural Networks\n",
    "\n",
    "In order to opmtimize the parameters, we first create a set of grid search parameters for the gradient boosted regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_number': [2, 3, 4],\n",
       " 'node_number': [20, 30, 60],\n",
       " 'resnet': [True, False]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={\n",
    "    'layer_number':[2,3,4],\n",
    "    'node_number':[20,30,60],\n",
    "    'resnet':[True, False]\n",
    "}\n",
    "\n",
    "L2_WEIGHT_DECAY=0.02\n",
    "BATCH_NORM_DECAY=0.999\n",
    "BATCH_NORM_EPSILON=0.0001\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_gridsearch_resnetdense(PATH, *params):\n",
    "    output_param=[]\n",
    "    import os\n",
    "    for i in params[0]['layer_number']:\n",
    "        for j in params[0]['node_number']:\n",
    "            for k in params[0]['resnet']:\n",
    "                output_param.append([i,j,k])\n",
    "    df=pd.DataFrame(output_param, columns=['layer_number','node_number','resnet'])\n",
    "    df.to_csv(os.path.join(PATH, 'resnetdense_param.txt'), sep=\"\\t\")\n",
    "    return(df)\n",
    "\n",
    "params_matrix_resnetdense=param_gridsearch_resnetdense(PATH, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "\n",
    "L2_WEIGHT_DECAY=0.02\n",
    "BATCH_NORM_DECAY=0.999\n",
    "BATCH_NORM_EPSILON=0.0001\n",
    "\n",
    "params={\n",
    "    'layer_number':[2,4,6],\n",
    "    'node_number':[20,30,60],\n",
    "    'dropout':[0,0.2]\n",
    "    'resnet':[True, False]\n",
    "}\n",
    "\n",
    "#layer_number=[2,4,6]\n",
    "#node_number=[20,30,60]\n",
    "#dropout=[0,0.2]\n",
    "#resnet=[True, False]\n",
    "\n",
    "def param_gridsearch_resnetdense(PATH, *params):\n",
    "    output_param=[]\n",
    "    import os\n",
    "    for i in params[0]['layer_number']:\n",
    "        for j in params[0]['node_number']:\n",
    "            for k in params[0]['resnet']:\n",
    "                for m in params[0]['dropout']:\n",
    "                    output_param.append([i,j,k,m])\n",
    "    df=pd.DataFrame(output_param, columns=['layer_number','node_number','resnet', 'dropout'])\n",
    "    df.to_csv(os.path.join(PATH, 'resnetdense_param.txt'), sep=\"\\t\")\n",
    "    return(df)\n",
    "\n",
    "params_matrix_resnetdense=param_gridsearch_resnetdense(PATH,params)\n",
    "\n",
    "def identity_block_resnet(input_shape, layer_number, node_number, dropout, resnet=True):\n",
    "    input_tensor = layers.Input(shape=[ input_shape[1], ])    \n",
    "    x = layers.Dense(node_number,input_dim=input_shape[1], use_bias=False, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(input_tensor)\n",
    "    x = layers.BatchNormalization(axis=-1, momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    for j in range(layer_number):\n",
    "        x = layers.Dropout( dropout)(x)\n",
    "        x = layers.Dense(node_number, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "        x = layers.BatchNormalization(axis=-1, momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Dense(input_shape[1], use_bias=False, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "    x = layers.BatchNormalization(axis=-1, momentum=BATCH_NORM_DECAY, epsilon=BATCH_NORM_EPSILON)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    if resnet:\n",
    "        x = layers.add([x, input_tensor])\n",
    "    x = layers.Dense(1, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(L2_WEIGHT_DECAY))(x)\n",
    "\n",
    "    return models.Model(input_tensor, x, name='ResNet Sequential')\n",
    "\n",
    "\n",
    "def predictor_resnet(X_train_val,y_train_val, X_test,y_test,params_matrix):\n",
    "    mse_grid=[]\n",
    "    for i in range(params_matrix.shape[0]):\n",
    "        print(i/params_matrix.shape[0])\n",
    "        params=params_matrix.iloc[i,:].to_dict()\n",
    "        print(params)\n",
    "    \n",
    "        model=identity_block_resnet(X_train_val.shape, **params)\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "        model.fit(X_train_val, y_train_val, epochs = 5, batch_size = 32, validation_split=0.2)\n",
    "    \n",
    "        mse = mean_squared_error(y_test, np.squeeze(model.predict(X_test)))\n",
    "        mse_grid.append(mse)\n",
    "\n",
    "    best_params=params_matrix.iloc[np.argmin(mse_grid),:].to_dict()\n",
    "    model=identity_block_resnet(X_train_val.shape, **best_params)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    model.fit(X_train_val, y_train_val, epochs = 5, batch_size = 32, validation_split=0.2)\n",
    "    return(best_params, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report and Results storage\n",
    "\n",
    "In order to opmtimize the parameters, we first create a set of grid search parameters for the gradient boosted regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_best_param(PATH, postfix,model_type, best_params):\n",
    "    if model_type=='xgr':\n",
    "        df=pd.DataFrame(best_params, columns=['n_estimators','max_depth','min_samples_split','learning_rate','loss'], index=['xgr'])\n",
    "        df.to_csv(os.path.join(PATH, 'best_params_gbregressor_'+postfix+'_'+model_type+'.txt'), sep=\"\\t\")\n",
    "    elif model_type=='lasso':\n",
    "        df=pd.DataFrame(best_params, columns=['alpha'], index=['lasso'])\n",
    "        df.to_csv(os.path.join(PATH, 'best_params_lasso_'+postfix+'_'+model_type+'.txt'), sep=\"\\t\")    \n",
    "    elif model_type=='resnet':\n",
    "        df=pd.DataFrame(best_params, columns=['layer_number','node_number','resnet', 'dropout'], index=['resnet'])\n",
    "        df.to_csv(os.path.join(PATH, 'best_params_resnet_'+postfix+'_'+model_type+'.txt'), sep=\"\\t\")\n",
    "        \n",
    "        \n",
    "def store_prediction(model,y_test, X_test,model_type, PATH, postfix):\n",
    "    df=pd.DataFrame(list(zip(np.squeeze(y_test),np.squeeze(model.predict(X_test)))), columns=['test','predicted'])\n",
    "    df.to_csv(os.path.join(PATH, 'prediction_'+model_type+'_'+postfix+'_'+model_type+'.txt'), sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models\n",
    "\n",
    "In order to opmtimize the parameters, we first create a set of grid search parameters for the gradient boosted regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_NoAB</th>\n",
       "      <th>y_NoAB</th>\n",
       "      <th>r_CAM-0.5</th>\n",
       "      <th>y_CAM-0.5</th>\n",
       "      <th>r_CAM-1</th>\n",
       "      <th>y_CAM-1</th>\n",
       "      <th>r_CAM-2</th>\n",
       "      <th>y_CAM-2</th>\n",
       "      <th>r_CIP-0.002</th>\n",
       "      <th>y_CIP-0.002</th>\n",
       "      <th>...</th>\n",
       "      <th>r_TET-0.6</th>\n",
       "      <th>y_TET-0.6</th>\n",
       "      <th>r_TET-1.25</th>\n",
       "      <th>y_TET-1.25</th>\n",
       "      <th>r_TRIM-0.125</th>\n",
       "      <th>y_TRIM-0.125</th>\n",
       "      <th>r_TRIM-0.25</th>\n",
       "      <th>y_TRIM-0.25</th>\n",
       "      <th>r_TRIM-0.5</th>\n",
       "      <th>y_TRIM-0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lane</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24742_1#1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.555188</td>\n",
       "      <td>-0.894984</td>\n",
       "      <td>-0.537717</td>\n",
       "      <td>-1.107236</td>\n",
       "      <td>-0.824196</td>\n",
       "      <td>-0.894818</td>\n",
       "      <td>-0.637241</td>\n",
       "      <td>-1.241845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166475</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>-0.359683</td>\n",
       "      <td>-0.122013</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>-1.859038</td>\n",
       "      <td>-0.704300</td>\n",
       "      <td>-3.234576</td>\n",
       "      <td>-0.492798</td>\n",
       "      <td>-1.187767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24742_1#2</td>\n",
       "      <td>0.104275</td>\n",
       "      <td>-0.623624</td>\n",
       "      <td>-0.171375</td>\n",
       "      <td>-0.341843</td>\n",
       "      <td>-0.124909</td>\n",
       "      <td>0.206825</td>\n",
       "      <td>-0.830909</td>\n",
       "      <td>1.894838</td>\n",
       "      <td>-0.006351</td>\n",
       "      <td>0.484449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.767449</td>\n",
       "      <td>3.515031</td>\n",
       "      <td>-1.562286</td>\n",
       "      <td>5.739422</td>\n",
       "      <td>-0.318986</td>\n",
       "      <td>0.495341</td>\n",
       "      <td>-0.339357</td>\n",
       "      <td>1.228346</td>\n",
       "      <td>-0.340873</td>\n",
       "      <td>3.262149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24742_1#3</td>\n",
       "      <td>-0.081769</td>\n",
       "      <td>-0.301323</td>\n",
       "      <td>-0.119350</td>\n",
       "      <td>0.078526</td>\n",
       "      <td>-0.127551</td>\n",
       "      <td>0.168754</td>\n",
       "      <td>-0.418040</td>\n",
       "      <td>0.443903</td>\n",
       "      <td>-0.290227</td>\n",
       "      <td>0.744871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.697390</td>\n",
       "      <td>3.488927</td>\n",
       "      <td>-1.532580</td>\n",
       "      <td>5.351141</td>\n",
       "      <td>-0.256452</td>\n",
       "      <td>0.771651</td>\n",
       "      <td>-0.497930</td>\n",
       "      <td>1.476964</td>\n",
       "      <td>-0.483559</td>\n",
       "      <td>3.626248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24742_1#4</td>\n",
       "      <td>-0.084430</td>\n",
       "      <td>-0.849137</td>\n",
       "      <td>-0.205950</td>\n",
       "      <td>-0.673437</td>\n",
       "      <td>-0.148708</td>\n",
       "      <td>-0.645597</td>\n",
       "      <td>-0.486796</td>\n",
       "      <td>-0.152780</td>\n",
       "      <td>-0.087412</td>\n",
       "      <td>-0.114168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.665094</td>\n",
       "      <td>2.380797</td>\n",
       "      <td>-1.246116</td>\n",
       "      <td>1.119005</td>\n",
       "      <td>-0.318859</td>\n",
       "      <td>-0.186104</td>\n",
       "      <td>-0.402424</td>\n",
       "      <td>1.191143</td>\n",
       "      <td>-0.555719</td>\n",
       "      <td>2.990016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24742_1#5</td>\n",
       "      <td>-0.243146</td>\n",
       "      <td>-0.591028</td>\n",
       "      <td>-0.183318</td>\n",
       "      <td>-0.762312</td>\n",
       "      <td>-0.206379</td>\n",
       "      <td>-0.601047</td>\n",
       "      <td>-0.750989</td>\n",
       "      <td>0.362407</td>\n",
       "      <td>-0.404123</td>\n",
       "      <td>0.457321</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.192005</td>\n",
       "      <td>3.974147</td>\n",
       "      <td>-2.211937</td>\n",
       "      <td>5.633334</td>\n",
       "      <td>-0.520739</td>\n",
       "      <td>-0.236159</td>\n",
       "      <td>-0.576419</td>\n",
       "      <td>1.004208</td>\n",
       "      <td>-0.731796</td>\n",
       "      <td>2.807436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27970_2#376</td>\n",
       "      <td>-0.255959</td>\n",
       "      <td>-0.918329</td>\n",
       "      <td>-0.433526</td>\n",
       "      <td>-0.624229</td>\n",
       "      <td>-0.567971</td>\n",
       "      <td>-0.249068</td>\n",
       "      <td>-0.799909</td>\n",
       "      <td>0.549171</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.327217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.520976</td>\n",
       "      <td>2.521096</td>\n",
       "      <td>-0.725536</td>\n",
       "      <td>3.014558</td>\n",
       "      <td>-0.269622</td>\n",
       "      <td>-1.172193</td>\n",
       "      <td>-0.396228</td>\n",
       "      <td>-0.768612</td>\n",
       "      <td>-0.273833</td>\n",
       "      <td>0.853602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27970_2#377</td>\n",
       "      <td>0.297314</td>\n",
       "      <td>-1.094470</td>\n",
       "      <td>0.143121</td>\n",
       "      <td>-0.941989</td>\n",
       "      <td>0.104264</td>\n",
       "      <td>-0.337694</td>\n",
       "      <td>-0.453345</td>\n",
       "      <td>1.043838</td>\n",
       "      <td>-0.218012</td>\n",
       "      <td>-0.341449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.611401</td>\n",
       "      <td>3.973458</td>\n",
       "      <td>-1.577047</td>\n",
       "      <td>6.072258</td>\n",
       "      <td>-0.244862</td>\n",
       "      <td>-1.025116</td>\n",
       "      <td>-0.178759</td>\n",
       "      <td>-0.494948</td>\n",
       "      <td>-0.097135</td>\n",
       "      <td>0.408245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27970_2#378</td>\n",
       "      <td>-0.626151</td>\n",
       "      <td>0.903940</td>\n",
       "      <td>-0.339344</td>\n",
       "      <td>1.155166</td>\n",
       "      <td>-0.700835</td>\n",
       "      <td>1.268132</td>\n",
       "      <td>-0.568980</td>\n",
       "      <td>2.634798</td>\n",
       "      <td>-0.073093</td>\n",
       "      <td>1.537021</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132368</td>\n",
       "      <td>5.478577</td>\n",
       "      <td>-1.833554</td>\n",
       "      <td>6.889389</td>\n",
       "      <td>0.529120</td>\n",
       "      <td>-2.920050</td>\n",
       "      <td>0.523254</td>\n",
       "      <td>-3.453022</td>\n",
       "      <td>0.518535</td>\n",
       "      <td>-2.495402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27970_2#379</td>\n",
       "      <td>-0.427584</td>\n",
       "      <td>-0.664362</td>\n",
       "      <td>-0.470603</td>\n",
       "      <td>-0.474903</td>\n",
       "      <td>-0.517777</td>\n",
       "      <td>-0.038596</td>\n",
       "      <td>-0.954015</td>\n",
       "      <td>0.493220</td>\n",
       "      <td>-0.457906</td>\n",
       "      <td>0.506936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969451</td>\n",
       "      <td>1.805810</td>\n",
       "      <td>-1.362812</td>\n",
       "      <td>3.163279</td>\n",
       "      <td>-0.393398</td>\n",
       "      <td>-0.460634</td>\n",
       "      <td>-0.267153</td>\n",
       "      <td>-0.402708</td>\n",
       "      <td>-0.350066</td>\n",
       "      <td>-0.173444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27970_2#380</td>\n",
       "      <td>-0.561561</td>\n",
       "      <td>-1.669569</td>\n",
       "      <td>-1.021559</td>\n",
       "      <td>-1.540225</td>\n",
       "      <td>-0.777222</td>\n",
       "      <td>-1.071390</td>\n",
       "      <td>-0.998329</td>\n",
       "      <td>0.320354</td>\n",
       "      <td>-0.786522</td>\n",
       "      <td>-0.240226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.688533</td>\n",
       "      <td>1.611064</td>\n",
       "      <td>-1.007557</td>\n",
       "      <td>3.160318</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>-1.307842</td>\n",
       "      <td>0.167454</td>\n",
       "      <td>-0.354068</td>\n",
       "      <td>-0.292514</td>\n",
       "      <td>0.425113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1659 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               r_NoAB    y_NoAB  r_CAM-0.5  y_CAM-0.5   r_CAM-1   y_CAM-1  \\\n",
       "Lane                                                                        \n",
       "24742_1#1         NaN       NaN  -0.555188  -0.894984 -0.537717 -1.107236   \n",
       "24742_1#2    0.104275 -0.623624  -0.171375  -0.341843 -0.124909  0.206825   \n",
       "24742_1#3   -0.081769 -0.301323  -0.119350   0.078526 -0.127551  0.168754   \n",
       "24742_1#4   -0.084430 -0.849137  -0.205950  -0.673437 -0.148708 -0.645597   \n",
       "24742_1#5   -0.243146 -0.591028  -0.183318  -0.762312 -0.206379 -0.601047   \n",
       "...               ...       ...        ...        ...       ...       ...   \n",
       "27970_2#376 -0.255959 -0.918329  -0.433526  -0.624229 -0.567971 -0.249068   \n",
       "27970_2#377  0.297314 -1.094470   0.143121  -0.941989  0.104264 -0.337694   \n",
       "27970_2#378 -0.626151  0.903940  -0.339344   1.155166 -0.700835  1.268132   \n",
       "27970_2#379 -0.427584 -0.664362  -0.470603  -0.474903 -0.517777 -0.038596   \n",
       "27970_2#380 -0.561561 -1.669569  -1.021559  -1.540225 -0.777222 -1.071390   \n",
       "\n",
       "              r_CAM-2   y_CAM-2  r_CIP-0.002  y_CIP-0.002  ...  r_TET-0.6  \\\n",
       "Lane                                                       ...              \n",
       "24742_1#1   -0.824196 -0.894818    -0.637241    -1.241845  ...  -0.166475   \n",
       "24742_1#2   -0.830909  1.894838    -0.006351     0.484449  ...  -0.767449   \n",
       "24742_1#3   -0.418040  0.443903    -0.290227     0.744871  ...  -0.697390   \n",
       "24742_1#4   -0.486796 -0.152780    -0.087412    -0.114168  ...  -0.665094   \n",
       "24742_1#5   -0.750989  0.362407    -0.404123     0.457321  ...  -1.192005   \n",
       "...               ...       ...          ...          ...  ...        ...   \n",
       "27970_2#376 -0.799909  0.549171     0.008598     0.327217  ...  -0.520976   \n",
       "27970_2#377 -0.453345  1.043838    -0.218012    -0.341449  ...  -0.611401   \n",
       "27970_2#378 -0.568980  2.634798    -0.073093     1.537021  ...  -1.132368   \n",
       "27970_2#379 -0.954015  0.493220    -0.457906     0.506936  ...  -0.969451   \n",
       "27970_2#380 -0.998329  0.320354    -0.786522    -0.240226  ...  -0.688533   \n",
       "\n",
       "             y_TET-0.6  r_TET-1.25  y_TET-1.25  r_TRIM-0.125  y_TRIM-0.125  \\\n",
       "Lane                                                                         \n",
       "24742_1#1     0.494444   -0.359683   -0.122013      0.084034     -1.859038   \n",
       "24742_1#2     3.515031   -1.562286    5.739422     -0.318986      0.495341   \n",
       "24742_1#3     3.488927   -1.532580    5.351141     -0.256452      0.771651   \n",
       "24742_1#4     2.380797   -1.246116    1.119005     -0.318859     -0.186104   \n",
       "24742_1#5     3.974147   -2.211937    5.633334     -0.520739     -0.236159   \n",
       "...                ...         ...         ...           ...           ...   \n",
       "27970_2#376   2.521096   -0.725536    3.014558     -0.269622     -1.172193   \n",
       "27970_2#377   3.973458   -1.577047    6.072258     -0.244862     -1.025116   \n",
       "27970_2#378   5.478577   -1.833554    6.889389      0.529120     -2.920050   \n",
       "27970_2#379   1.805810   -1.362812    3.163279     -0.393398     -0.460634   \n",
       "27970_2#380   1.611064   -1.007557    3.160318      0.025500     -1.307842   \n",
       "\n",
       "             r_TRIM-0.25  y_TRIM-0.25  r_TRIM-0.5  y_TRIM-0.5  \n",
       "Lane                                                           \n",
       "24742_1#1      -0.704300    -3.234576   -0.492798   -1.187767  \n",
       "24742_1#2      -0.339357     1.228346   -0.340873    3.262149  \n",
       "24742_1#3      -0.497930     1.476964   -0.483559    3.626248  \n",
       "24742_1#4      -0.402424     1.191143   -0.555719    2.990016  \n",
       "24742_1#5      -0.576419     1.004208   -0.731796    2.807436  \n",
       "...                  ...          ...         ...         ...  \n",
       "27970_2#376    -0.396228    -0.768612   -0.273833    0.853602  \n",
       "27970_2#377    -0.178759    -0.494948   -0.097135    0.408245  \n",
       "27970_2#378     0.523254    -3.453022    0.518535   -2.495402  \n",
       "27970_2#379    -0.267153    -0.402708   -0.350066   -0.173444  \n",
       "27970_2#380     0.167454    -0.354068   -0.292514    0.425113  \n",
       "\n",
       "[1659 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH=\"/Users/moradigd/Documents/Prediction/\"\n",
    "\n",
    "response='Metadata_median_NoAB.txt'\n",
    "features='pangene.txt'\n",
    "response_dataframe=pd.read_csv(os.path.join(PATH, response), index_col=0, sep=\"\\t\")\n",
    "response_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_matrix_resnetdense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-51bcdb6a5390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams_matrix_resnetdense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params_matrix_resnetdense' is not defined"
     ]
    }
   ],
   "source": [
    "params_matrix_resnetdense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "{'n_estimators': 100, 'max_depth': 2, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11938018144365509\n",
      "0.25\n",
      "{'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11666819223364616\n",
      "0.5\n",
      "{'n_estimators': 200, 'max_depth': 2, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11625315086643087\n",
      "0.75\n",
      "{'n_estimators': 200, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11397912188993914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "{'alpha': 1e-15}\n",
      "0.1\n",
      "{'alpha': 1e-10}\n",
      "0.2\n",
      "{'alpha': 1e-08}\n",
      "0.3\n",
      "{'alpha': 1e-05}\n",
      "0.4\n",
      "{'alpha': 0.0001}\n",
      "0.5\n",
      "{'alpha': 0.001}\n",
      "0.6\n",
      "{'alpha': 0.01}\n",
      "0.7\n",
      "{'alpha': 1.0}\n",
      "0.8\n",
      "{'alpha': 5.0}\n",
      "0.9\n",
      "{'alpha': 10.0}\n",
      "0.0\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 40s 39ms/step - loss: 1396.0017 - mean_absolute_error: 2.9868 - val_loss: 1272.7371 - val_mean_absolute_error: 1.9556\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1170.9353 - mean_absolute_error: 0.9061 - val_loss: 1070.7772 - val_mean_absolute_error: 1.0039\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 983.9585 - mean_absolute_error: 0.5003 - val_loss: 896.8139 - val_mean_absolute_error: 0.4590\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 823.2044 - mean_absolute_error: 0.4823 - val_loss: 748.6822 - val_mean_absolute_error: 0.3520\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 686.1508 - mean_absolute_error: 0.4072 - val_loss: 623.1504 - val_mean_absolute_error: 0.4381\n",
      "0.027777777777777776\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 26s 25ms/step - loss: 1387.2518 - mean_absolute_error: 3.4504 - val_loss: 1253.1006 - val_mean_absolute_error: 1.8024\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1148.7697 - mean_absolute_error: 0.9287 - val_loss: 1044.8762 - val_mean_absolute_error: 0.3981\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 958.0789 - mean_absolute_error: 0.5408 - val_loss: 870.1560 - val_mean_absolute_error: 0.4291\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 796.4649 - mean_absolute_error: 0.4577 - val_loss: 722.1467 - val_mean_absolute_error: 0.3207\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 660.3912 - mean_absolute_error: 0.4866 - val_loss: 598.1006 - val_mean_absolute_error: 0.4662\n",
      "0.05555555555555555\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 28s 27ms/step - loss: 1375.6151 - mean_absolute_error: 2.3643 - val_loss: 1248.3911 - val_mean_absolute_error: 1.5535\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1141.5323 - mean_absolute_error: 0.7851 - val_loss: 1036.5208 - val_mean_absolute_error: 0.7385\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 948.1556 - mean_absolute_error: 0.5365 - val_loss: 859.6427 - val_mean_absolute_error: 0.5013\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 785.7352 - mean_absolute_error: 0.4435 - val_loss: 711.8163 - val_mean_absolute_error: 0.5359\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 650.0862 - mean_absolute_error: 0.4455 - val_loss: 588.1910 - val_mean_absolute_error: 0.3426\n",
      "0.08333333333333333\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 32s 31ms/step - loss: 1419.4311 - mean_absolute_error: 4.8768 - val_loss: 1273.0480 - val_mean_absolute_error: 2.3053\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1166.8153 - mean_absolute_error: 1.0145 - val_loss: 1064.1803 - val_mean_absolute_error: 0.4641\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 977.8417 - mean_absolute_error: 0.4572 - val_loss: 890.2872 - val_mean_absolute_error: 0.3657\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 816.4058 - mean_absolute_error: 0.4123 - val_loss: 741.7859 - val_mean_absolute_error: 0.3696\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 679.3339 - mean_absolute_error: 0.4641 - val_loss: 616.1611 - val_mean_absolute_error: 0.3314\n",
      "0.1111111111111111\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 28s 27ms/step - loss: 1386.8219 - mean_absolute_error: 4.0492 - val_loss: 1229.8677 - val_mean_absolute_error: 1.7593\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1114.4052 - mean_absolute_error: 0.8028 - val_loss: 999.9655 - val_mean_absolute_error: 0.8866\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 903.2038 - mean_absolute_error: 0.5023 - val_loss: 806.7236 - val_mean_absolute_error: 0.4040\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 727.1423 - mean_absolute_error: 0.4264 - val_loss: 647.7245 - val_mean_absolute_error: 0.4005\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 582.5855 - mean_absolute_error: 0.4413 - val_loss: 517.7953 - val_mean_absolute_error: 0.4565\n",
      "0.1388888888888889\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 27s 27ms/step - loss: 1429.4188 - mean_absolute_error: 5.3310 - val_loss: 1267.7274 - val_mean_absolute_error: 3.6179\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1150.9084 - mean_absolute_error: 1.3164 - val_loss: 1040.2272 - val_mean_absolute_error: 0.4002\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 947.8238 - mean_absolute_error: 0.5168 - val_loss: 853.9485 - val_mean_absolute_error: 0.3643\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 775.3140 - mean_absolute_error: 0.4298 - val_loss: 696.1210 - val_mean_absolute_error: 0.3529\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 630.4176 - mean_absolute_error: 0.4230 - val_loss: 564.4373 - val_mean_absolute_error: 0.3105\n",
      "0.16666666666666666\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 27s 26ms/step - loss: 1393.9396 - mean_absolute_error: 4.7862 - val_loss: 1268.1878 - val_mean_absolute_error: 6.5646\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1105.6596 - mean_absolute_error: 1.0488 - val_loss: 987.0868 - val_mean_absolute_error: 0.4983\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 889.1619 - mean_absolute_error: 0.4711 - val_loss: 791.4247 - val_mean_absolute_error: 0.4284\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 711.0913 - mean_absolute_error: 0.3769 - val_loss: 631.2397 - val_mean_absolute_error: 0.3363\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 566.0565 - mean_absolute_error: 0.3608 - val_loss: 501.4478 - val_mean_absolute_error: 0.3744\n",
      "0.19444444444444445\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 28s 27ms/step - loss: 1394.6092 - mean_absolute_error: 4.7709 - val_loss: 1232.6403 - val_mean_absolute_error: 3.2695\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1104.6511 - mean_absolute_error: 0.9970 - val_loss: 985.7950 - val_mean_absolute_error: 0.3488\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 888.0923 - mean_absolute_error: 0.3991 - val_loss: 790.3502 - val_mean_absolute_error: 0.3106\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 710.2191 - mean_absolute_error: 0.3883 - val_loss: 630.3937 - val_mean_absolute_error: 0.3208\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 565.4498 - mean_absolute_error: 0.4184 - val_loss: 500.8798 - val_mean_absolute_error: 0.3735\n",
      "0.2222222222222222\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 35s 35ms/step - loss: 1336.3226 - mean_absolute_error: 3.5755 - val_loss: 1136.8003 - val_mean_absolute_error: 1.7464\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 984.2697 - mean_absolute_error: 0.8641 - val_loss: 837.1122 - val_mean_absolute_error: 0.7563\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 721.8278 - mean_absolute_error: 0.4639 - val_loss: 610.8508 - val_mean_absolute_error: 0.5537\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 5s 5ms/step - loss: 525.5295 - mean_absolute_error: 0.5598 - val_loss: 443.7167 - val_mean_absolute_error: 0.7316\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 381.2236 - mean_absolute_error: 0.6672 - val_loss: 321.7391 - val_mean_absolute_error: 0.8590\n",
      "0.25\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 30s 29ms/step - loss: 1360.8854 - mean_absolute_error: 4.6045 - val_loss: 1155.9816 - val_mean_absolute_error: 1.1575\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1014.8755 - mean_absolute_error: 1.1893 - val_loss: 872.6562 - val_mean_absolute_error: 0.6978\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 759.1967 - mean_absolute_error: 0.5641 - val_loss: 648.2490 - val_mean_absolute_error: 0.3492\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 561.7029 - mean_absolute_error: 0.5205 - val_loss: 477.2927 - val_mean_absolute_error: 0.3617\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 412.3031 - mean_absolute_error: 0.5660 - val_loss: 348.8985 - val_mean_absolute_error: 0.3479\n",
      "0.2777777777777778\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 30s 29ms/step - loss: 1349.6699 - mean_absolute_error: 4.7610 - val_loss: 1168.9130 - val_mean_absolute_error: 5.1324\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 990.3037 - mean_absolute_error: 0.9371 - val_loss: 844.8460 - val_mean_absolute_error: 0.4306\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 730.4171 - mean_absolute_error: 0.4188 - val_loss: 619.0865 - val_mean_absolute_error: 0.3297\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 532.9085 - mean_absolute_error: 0.4020 - val_loss: 449.6258 - val_mean_absolute_error: 0.3635\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 385.8355 - mean_absolute_error: 0.4736 - val_loss: 324.3164 - val_mean_absolute_error: 0.3520\n",
      "0.3055555555555556\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 35s 34ms/step - loss: 1345.5667 - mean_absolute_error: 4.4655 - val_loss: 1136.6117 - val_mean_absolute_error: 0.9248\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 990.4811 - mean_absolute_error: 0.9522 - val_loss: 845.2710 - val_mean_absolute_error: 0.4976\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 731.0252 - mean_absolute_error: 0.4938 - val_loss: 619.7868 - val_mean_absolute_error: 0.3642\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 5s 5ms/step - loss: 533.6521 - mean_absolute_error: 0.4563 - val_loss: 450.2129 - val_mean_absolute_error: 0.3801\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 5s 5ms/step - loss: 386.4807 - mean_absolute_error: 0.5020 - val_loss: 324.8362 - val_mean_absolute_error: 0.3273\n",
      "0.3333333333333333\n",
      "{'layer_number': 4, 'node_number': 20, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 29s 28ms/step - loss: 1450.5481 - mean_absolute_error: 6.1324 - val_loss: 1284.2360 - val_mean_absolute_error: 2.6876\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1180.7643 - mean_absolute_error: 1.2827 - val_loss: 1080.6139 - val_mean_absolute_error: 0.9200\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 994.8582 - mean_absolute_error: 0.4847 - val_loss: 908.3205 - val_mean_absolute_error: 0.3241\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 835.0299 - mean_absolute_error: 0.3647 - val_loss: 760.9625 - val_mean_absolute_error: 0.3910\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 698.3288 - mean_absolute_error: 0.3815 - val_loss: 635.2047 - val_mean_absolute_error: 0.3479\n",
      "0.3611111111111111\n",
      "{'layer_number': 4, 'node_number': 20, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 31s 30ms/step - loss: 1417.6228 - mean_absolute_error: 5.0215 - val_loss: 1256.7956 - val_mean_absolute_error: 0.5217\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 5s 4ms/step - loss: 1157.3787 - mean_absolute_error: 0.9860 - val_loss: 1053.4666 - val_mean_absolute_error: 0.4629\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 966.1744 - mean_absolute_error: 0.4467 - val_loss: 877.8614 - val_mean_absolute_error: 0.3403\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 803.8006 - mean_absolute_error: 0.4100 - val_loss: 729.1485 - val_mean_absolute_error: 0.3458\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 666.8613 - mean_absolute_error: 0.4034 - val_loss: 604.2798 - val_mean_absolute_error: 0.4502\n",
      "0.3888888888888889\n",
      "{'layer_number': 4, 'node_number': 20, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 31s 30ms/step - loss: 1416.2875 - mean_absolute_error: 4.7735 - val_loss: 1279.6144 - val_mean_absolute_error: 3.7977\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1162.1139 - mean_absolute_error: 1.0138 - val_loss: 1058.3226 - val_mean_absolute_error: 0.3609\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 971.2998 - mean_absolute_error: 0.3840 - val_loss: 883.2650 - val_mean_absolute_error: 0.3395\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 809.1969 - mean_absolute_error: 0.3629 - val_loss: 734.4954 - val_mean_absolute_error: 0.3140\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 672.1002 - mean_absolute_error: 0.3950 - val_loss: 609.2552 - val_mean_absolute_error: 0.3683\n",
      "0.4166666666666667\n",
      "{'layer_number': 4, 'node_number': 20, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 30s 29ms/step - loss: 1385.6510 - mean_absolute_error: 2.7760 - val_loss: 1254.5105 - val_mean_absolute_error: 0.8615\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1152.9287 - mean_absolute_error: 0.7817 - val_loss: 1049.2049 - val_mean_absolute_error: 0.6282\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 961.2203 - mean_absolute_error: 0.4907 - val_loss: 872.6337 - val_mean_absolute_error: 0.3579\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 798.7164 - mean_absolute_error: 0.5196 - val_loss: 724.0741 - val_mean_absolute_error: 0.4327\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 661.9744 - mean_absolute_error: 0.4988 - val_loss: 599.3456 - val_mean_absolute_error: 0.3226\n",
      "0.4444444444444444\n",
      "{'layer_number': 4, 'node_number': 30, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 40s 39ms/step - loss: 1397.0196 - mean_absolute_error: 4.8150 - val_loss: 1222.3928 - val_mean_absolute_error: 1.3091\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1106.7617 - mean_absolute_error: 0.9637 - val_loss: 989.4401 - val_mean_absolute_error: 0.4836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 892.4627 - mean_absolute_error: 0.4597 - val_loss: 795.4957 - val_mean_absolute_error: 0.3697\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 715.7085 - mean_absolute_error: 0.3850 - val_loss: 636.2660 - val_mean_absolute_error: 0.3636\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 571.3855 - mean_absolute_error: 0.4060 - val_loss: 506.8410 - val_mean_absolute_error: 0.3182\n",
      "0.4722222222222222\n",
      "{'layer_number': 4, 'node_number': 30, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 33s 33ms/step - loss: 1426.2345 - mean_absolute_error: 5.9906 - val_loss: 1239.0638 - val_mean_absolute_error: 2.2281\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1123.5113 - mean_absolute_error: 1.2422 - val_loss: 1006.5647 - val_mean_absolute_error: 0.5329\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 909.7996 - mean_absolute_error: 0.4433 - val_loss: 812.6279 - val_mean_absolute_error: 0.3233\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 732.3365 - mean_absolute_error: 0.3964 - val_loss: 652.0778 - val_mean_absolute_error: 0.3063\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 586.3103 - mean_absolute_error: 0.3762 - val_loss: 520.7748 - val_mean_absolute_error: 0.3083\n",
      "0.5\n",
      "{'layer_number': 4, 'node_number': 30, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 40s 39ms/step - loss: 1372.5572 - mean_absolute_error: 3.4120 - val_loss: 1239.8255 - val_mean_absolute_error: 4.6610\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1096.6358 - mean_absolute_error: 0.7891 - val_loss: 978.2081 - val_mean_absolute_error: 0.7451\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 879.6115 - mean_absolute_error: 0.4131 - val_loss: 781.9180 - val_mean_absolute_error: 0.3697\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 702.0890 - mean_absolute_error: 0.3737 - val_loss: 622.7932 - val_mean_absolute_error: 0.3178\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 558.3849 - mean_absolute_error: 0.4018 - val_loss: 494.4736 - val_mean_absolute_error: 0.3813\n",
      "0.5277777777777778\n",
      "{'layer_number': 4, 'node_number': 30, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 31s 30ms/step - loss: 1395.6220 - mean_absolute_error: 5.0153 - val_loss: 1232.1388 - val_mean_absolute_error: 3.9048\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1099.4834 - mean_absolute_error: 1.1404 - val_loss: 979.2071 - val_mean_absolute_error: 0.6182\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 880.5393 - mean_absolute_error: 0.4597 - val_loss: 782.2820 - val_mean_absolute_error: 0.3248\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 702.0732 - mean_absolute_error: 0.4016 - val_loss: 622.3319 - val_mean_absolute_error: 0.3533\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 557.5820 - mean_absolute_error: 0.3998 - val_loss: 493.2979 - val_mean_absolute_error: 0.3269\n",
      "0.5555555555555556\n",
      "{'layer_number': 4, 'node_number': 60, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 33s 32ms/step - loss: 1358.1630 - mean_absolute_error: 4.6739 - val_loss: 1163.6172 - val_mean_absolute_error: 3.8817\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1001.6993 - mean_absolute_error: 1.0340 - val_loss: 856.4727 - val_mean_absolute_error: 0.8959\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 741.1471 - mean_absolute_error: 0.4380 - val_loss: 629.7182 - val_mean_absolute_error: 0.4761\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 543.0801 - mean_absolute_error: 0.4414 - val_loss: 459.5768 - val_mean_absolute_error: 0.5604\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 395.3602 - mean_absolute_error: 0.5400 - val_loss: 333.4470 - val_mean_absolute_error: 0.4314\n",
      "0.5833333333333334\n",
      "{'layer_number': 4, 'node_number': 60, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 42s 41ms/step - loss: 1383.9262 - mean_absolute_error: 5.7276 - val_loss: 1178.7072 - val_mean_absolute_error: 4.0622\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1021.0436 - mean_absolute_error: 1.2430 - val_loss: 877.8575 - val_mean_absolute_error: 0.4408\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 764.4585 - mean_absolute_error: 0.4938 - val_loss: 653.3364 - val_mean_absolute_error: 0.4167\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 566.2758 - mean_absolute_error: 0.4866 - val_loss: 481.5089 - val_mean_absolute_error: 0.3560\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 416.3609 - mean_absolute_error: 0.5962 - val_loss: 352.7490 - val_mean_absolute_error: 0.4342\n",
      "0.6111111111111112\n",
      "{'layer_number': 4, 'node_number': 60, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 36s 35ms/step - loss: 1317.1642 - mean_absolute_error: 2.5558 - val_loss: 1125.9779 - val_mean_absolute_error: 2.0206\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 970.2336 - mean_absolute_error: 0.7054 - val_loss: 822.5096 - val_mean_absolute_error: 0.5045\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 708.1234 - mean_absolute_error: 0.5570 - val_loss: 598.0972 - val_mean_absolute_error: 0.5877\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 514.0667 - mean_absolute_error: 0.6545 - val_loss: 433.2295 - val_mean_absolute_error: 0.5559\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 372.8547 - mean_absolute_error: 0.8167 - val_loss: 314.5635 - val_mean_absolute_error: 0.8445\n",
      "0.6388888888888888\n",
      "{'layer_number': 4, 'node_number': 60, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 39s 38ms/step - loss: 1343.0646 - mean_absolute_error: 4.3370 - val_loss: 1132.3994 - val_mean_absolute_error: 0.6100\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 985.3493 - mean_absolute_error: 0.9963 - val_loss: 838.3695 - val_mean_absolute_error: 0.4559\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 723.9376 - mean_absolute_error: 0.5393 - val_loss: 612.6879 - val_mean_absolute_error: 0.3887\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 526.9682 - mean_absolute_error: 0.4667 - val_loss: 444.1349 - val_mean_absolute_error: 0.3523\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 381.4288 - mean_absolute_error: 0.6046 - val_loss: 320.5272 - val_mean_absolute_error: 0.3538\n",
      "0.6666666666666666\n",
      "{'layer_number': 6, 'node_number': 20, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 31s 30ms/step - loss: 1436.3780 - mean_absolute_error: 5.8512 - val_loss: 1340.6267 - val_mean_absolute_error: 7.5704\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1163.8599 - mean_absolute_error: 1.1135 - val_loss: 1060.4859 - val_mean_absolute_error: 0.4167\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 973.8727 - mean_absolute_error: 0.4513 - val_loss: 886.2284 - val_mean_absolute_error: 0.3293\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 812.5041 - mean_absolute_error: 0.3970 - val_loss: 738.1139 - val_mean_absolute_error: 0.3349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 675.8108 - mean_absolute_error: 0.3831 - val_loss: 613.0959 - val_mean_absolute_error: 0.3451\n",
      "0.6944444444444444\n",
      "{'layer_number': 6, 'node_number': 20, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 32s 31ms/step - loss: 1433.4595 - mean_absolute_error: 5.6571 - val_loss: 1266.3481 - val_mean_absolute_error: 2.2000\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1164.5039 - mean_absolute_error: 1.2485 - val_loss: 1060.2932 - val_mean_absolute_error: 0.3717\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 973.5135 - mean_absolute_error: 0.4344 - val_loss: 885.6188 - val_mean_absolute_error: 0.4339\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 811.4222 - mean_absolute_error: 0.4010 - val_loss: 736.6744 - val_mean_absolute_error: 0.3391\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 674.1584 - mean_absolute_error: 0.3940 - val_loss: 611.1709 - val_mean_absolute_error: 0.3183\n",
      "0.7222222222222222\n",
      "{'layer_number': 6, 'node_number': 20, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 33s 32ms/step - loss: 1417.4628 - mean_absolute_error: 4.6238 - val_loss: 1289.6426 - val_mean_absolute_error: 4.4786\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1166.1818 - mean_absolute_error: 0.9922 - val_loss: 1063.4247 - val_mean_absolute_error: 0.4827\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 976.8393 - mean_absolute_error: 0.4210 - val_loss: 889.2460 - val_mean_absolute_error: 0.3654\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 815.2556 - mean_absolute_error: 0.3507 - val_loss: 740.8298 - val_mean_absolute_error: 0.3920\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 678.1641 - mean_absolute_error: 0.3500 - val_loss: 615.1681 - val_mean_absolute_error: 0.3016\n",
      "0.75\n",
      "{'layer_number': 6, 'node_number': 20, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 42s 41ms/step - loss: 1375.7990 - mean_absolute_error: 2.5329 - val_loss: 1244.4244 - val_mean_absolute_error: 0.7893\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1140.9101 - mean_absolute_error: 0.7564 - val_loss: 1035.5889 - val_mean_absolute_error: 0.4016\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 947.9014 - mean_absolute_error: 0.5528 - val_loss: 859.3009 - val_mean_absolute_error: 0.3740\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 785.8614 - mean_absolute_error: 0.4944 - val_loss: 711.8956 - val_mean_absolute_error: 0.4583\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 650.6014 - mean_absolute_error: 0.5370 - val_loss: 588.7894 - val_mean_absolute_error: 0.3980\n",
      "0.7777777777777778\n",
      "{'layer_number': 6, 'node_number': 30, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 38s 37ms/step - loss: 1425.8563 - mean_absolute_error: 5.9904 - val_loss: 1351.9357 - val_mean_absolute_error: 10.2467\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1118.9655 - mean_absolute_error: 1.2529 - val_loss: 1000.6211 - val_mean_absolute_error: 0.6084\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 902.9385 - mean_absolute_error: 0.4298 - val_loss: 805.3504 - val_mean_absolute_error: 0.3879\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 724.9586 - mean_absolute_error: 0.3898 - val_loss: 644.8870 - val_mean_absolute_error: 0.3369\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 579.3938 - mean_absolute_error: 0.3973 - val_loss: 514.2493 - val_mean_absolute_error: 0.3430\n",
      "0.8055555555555556\n",
      "{'layer_number': 6, 'node_number': 30, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 39s 38ms/step - loss: 1360.3344 - mean_absolute_error: 2.4331 - val_loss: 1210.7022 - val_mean_absolute_error: 1.1562\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1091.2765 - mean_absolute_error: 0.7680 - val_loss: 971.7101 - val_mean_absolute_error: 0.6828\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 873.3780 - mean_absolute_error: 0.5673 - val_loss: 775.3774 - val_mean_absolute_error: 0.3819\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 695.9542 - mean_absolute_error: 0.5422 - val_loss: 616.7996 - val_mean_absolute_error: 0.3689\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 553.4278 - mean_absolute_error: 0.7067 - val_loss: 489.5375 - val_mean_absolute_error: 0.3263\n",
      "0.8333333333333334\n",
      "{'layer_number': 6, 'node_number': 30, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 39s 38ms/step - loss: 1351.8565 - mean_absolute_error: 1.6965 - val_loss: 1209.7264 - val_mean_absolute_error: 1.8831\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1083.8113 - mean_absolute_error: 0.6410 - val_loss: 963.2873 - val_mean_absolute_error: 0.5654\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 864.9192 - mean_absolute_error: 0.6778 - val_loss: 767.3984 - val_mean_absolute_error: 0.6184\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 689.1233 - mean_absolute_error: 0.8693 - val_loss: 610.5174 - val_mean_absolute_error: 0.5945\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 548.9719 - mean_absolute_error: 1.0065 - val_loss: 486.4730 - val_mean_absolute_error: 0.8688\n",
      "0.8611111111111112\n",
      "{'layer_number': 6, 'node_number': 30, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 40s 39ms/step - loss: 1370.1788 - mean_absolute_error: 2.9736 - val_loss: 1219.9325 - val_mean_absolute_error: 1.8446\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1098.6572 - mean_absolute_error: 0.7322 - val_loss: 979.0088 - val_mean_absolute_error: 0.3834\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 880.6324 - mean_absolute_error: 0.4547 - val_loss: 782.5930 - val_mean_absolute_error: 0.3892\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 702.6204 - mean_absolute_error: 0.4538 - val_loss: 623.0141 - val_mean_absolute_error: 0.3195\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 558.8716 - mean_absolute_error: 0.5687 - val_loss: 494.6725 - val_mean_absolute_error: 0.3276\n",
      "0.8888888888888888\n",
      "{'layer_number': 6, 'node_number': 60, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 41s 40ms/step - loss: 1331.3474 - mean_absolute_error: 2.9504 - val_loss: 1140.6200 - val_mean_absolute_error: 1.5949\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 989.0594 - mean_absolute_error: 0.8010 - val_loss: 843.1963 - val_mean_absolute_error: 0.5333\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 728.8063 - mean_absolute_error: 0.5410 - val_loss: 618.7848 - val_mean_absolute_error: 0.7286\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 533.2664 - mean_absolute_error: 0.6749 - val_loss: 451.2901 - val_mean_absolute_error: 0.6521\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 389.1660 - mean_absolute_error: 0.7662 - val_loss: 329.0304 - val_mean_absolute_error: 0.6487\n",
      "0.9166666666666666\n",
      "{'layer_number': 6, 'node_number': 60, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 44s 43ms/step - loss: 1397.7159 - mean_absolute_error: 6.0405 - val_loss: 1175.7945 - val_mean_absolute_error: 2.0458\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 5s 5ms/step - loss: 1035.0937 - mean_absolute_error: 1.3090 - val_loss: 893.3210 - val_mean_absolute_error: 0.3363\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 780.7416 - mean_absolute_error: 0.4907 - val_loss: 669.8517 - val_mean_absolute_error: 0.3474\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 582.5641 - mean_absolute_error: 0.4732 - val_loss: 497.3742 - val_mean_absolute_error: 0.3960\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 431.1512 - mean_absolute_error: 0.4893 - val_loss: 366.6976 - val_mean_absolute_error: 0.3253\n",
      "0.9444444444444444\n",
      "{'layer_number': 6, 'node_number': 60, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 40s 39ms/step - loss: 1361.8620 - mean_absolute_error: 4.9411 - val_loss: 1188.4486 - val_mean_absolute_error: 6.0223\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1001.9821 - mean_absolute_error: 0.9969 - val_loss: 856.6175 - val_mean_absolute_error: 0.5602\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 741.8084 - mean_absolute_error: 0.4244 - val_loss: 630.2005 - val_mean_absolute_error: 0.3719\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 543.6545 - mean_absolute_error: 0.4083 - val_loss: 460.0030 - val_mean_absolute_error: 0.4073\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 395.8063 - mean_absolute_error: 0.4544 - val_loss: 333.8948 - val_mean_absolute_error: 0.3767\n",
      "0.9722222222222222\n",
      "{'layer_number': 6, 'node_number': 60, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 45s 44ms/step - loss: 1356.6873 - mean_absolute_error: 4.8699 - val_loss: 1141.8469 - val_mean_absolute_error: 1.5988\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 993.2053 - mean_absolute_error: 1.0639 - val_loss: 846.1112 - val_mean_absolute_error: 0.4661\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 731.2964 - mean_absolute_error: 0.4913 - val_loss: 619.7175 - val_mean_absolute_error: 0.3524\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 533.7699 - mean_absolute_error: 0.5105 - val_loss: 450.5282 - val_mean_absolute_error: 0.3594\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 387.2480 - mean_absolute_error: 0.5244 - val_loss: 326.1038 - val_mean_absolute_error: 0.4353\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 49s 47ms/step - loss: 1420.8306 - mean_absolute_error: 5.7452 - val_loss: 1241.1567 - val_mean_absolute_error: 3.0271\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1120.5554 - mean_absolute_error: 1.2025 - val_loss: 1003.5479 - val_mean_absolute_error: 0.4747\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 906.8484 - mean_absolute_error: 0.4536 - val_loss: 809.7566 - val_mean_absolute_error: 0.3462\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 729.5234 - mean_absolute_error: 0.4088 - val_loss: 649.3530 - val_mean_absolute_error: 0.3159\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 583.7202 - mean_absolute_error: 0.3818 - val_loss: 518.2849 - val_mean_absolute_error: 0.3068\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH=\"/Users/moradigd/Documents/Prediction/\"\n",
    "\n",
    "response='Metadata_median_NoAB.txt'\n",
    "features='pangene.txt'\n",
    "response_dataframe=pd.read_csv(os.path.join(PATH, response), index_col=0, sep=\"\\t\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#for j in range(10,response_dataframe.shape[1]):\n",
    "for j in range(0,1):\n",
    "    print(j)\n",
    "    #input_dataset=join_feature_response(features, response,PATH, i)\n",
    "\n",
    "    X_train=pd.read_csv(os.path.join(PATH, 'X_train_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "    X_test=pd.read_csv(os.path.join(PATH, 'X_test_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "\n",
    "    y_train=pd.read_csv(os.path.join(PATH, 'y_train_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "    y_test=pd.read_csv(os.path.join(PATH, 'y_test_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "\n",
    "    X_train=X_train.to_numpy()\n",
    "    X_test=X_test.to_numpy()\n",
    "    y_train=y_train.to_numpy()\n",
    "    y_test=y_test.to_numpy()\n",
    "    \n",
    "    best_params, model = predictor_boostingregressor(X_train,y_train, X_test,y_test,params_matrix_regressor)\n",
    "    \n",
    "    store_best_param(PATH, response_dataframe.columns[j], 'xgr', best_params)\n",
    "    store_prediction(model,y_test, X_test,'xgr', PATH,response_dataframe.columns[j])\n",
    "    \n",
    "    best_params, model = predictor_lasso(X_train,y_train, X_test,y_test,params_matrix_lasso)    \n",
    "\n",
    "    store_best_param(PATH, response_dataframe.columns[j], 'lasso', best_params)\n",
    "    store_prediction(model,y_test, X_test,'lasso', PATH,response_dataframe.columns[j])\n",
    "    \n",
    "    #best_params, model = predictor_cnn(X_train,y_train, X_test,y_test,params_matrix_resnetcnn)    \n",
    "\n",
    "    #store_best_param(PATH, response_dataframe.columns[j], 'cnn', best_params)\n",
    "    #store_prediction(model,y_test, np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1)),'cnn', PATH,response_dataframe.columns[j])\n",
    "    \n",
    "    best_params, model = predictor_resnet(X_train,y_train, X_test,y_test,params_matrix_resnetdense)\n",
    "    \n",
    "    store_best_param(PATH, response_dataframe.columns[j], 'resnet', best_params)\n",
    "    store_prediction(model,y_test, X_test,'resnet', PATH,response_dataframe.columns[j])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_number</th>\n",
       "      <th>node_number</th>\n",
       "      <th>resnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer_number  node_number  resnet\n",
       "0              2           20    True\n",
       "1              2           20   False\n",
       "2              2           30    True\n",
       "3              2           30   False\n",
       "4              2           60    True\n",
       "5              2           60   False\n",
       "6              3           20    True\n",
       "7              3           20   False\n",
       "8              3           30    True\n",
       "9              3           30   False\n",
       "10             3           60    True\n",
       "11             3           60   False\n",
       "12             4           20    True\n",
       "13             4           20   False\n",
       "14             4           30    True\n",
       "15             4           30   False\n",
       "16             4           60    True\n",
       "17             4           60   False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_matrix_resnetdense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': True, 'dropout': 0.0}\n",
      "WARNING:tensorflow:From /Users/moradigd/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 5s 5ms/step - loss: 1436.3395 - mean_absolute_error: 5.4887 - val_loss: 1320.8926 - val_mean_absolute_error: 6.2644\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1176.1628 - mean_absolute_error: 1.1920 - val_loss: 1075.4602 - val_mean_absolute_error: 0.8740\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 989.4612 - mean_absolute_error: 0.5396 - val_loss: 902.4669 - val_mean_absolute_error: 0.3811\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 828.8850 - mean_absolute_error: 0.3682 - val_loss: 754.5133 - val_mean_absolute_error: 0.3596\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 691.8752 - mean_absolute_error: 0.3571 - val_loss: 628.7202 - val_mean_absolute_error: 0.3180\n",
      "0.027777777777777776\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': True, 'dropout': 0.2}\n",
      "WARNING:tensorflow:From /Users/moradigd/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1396.4590 - mean_absolute_error: 3.5535 - val_loss: 1261.7371 - val_mean_absolute_error: 1.5108\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1162.1401 - mean_absolute_error: 0.8991 - val_loss: 1060.5430 - val_mean_absolute_error: 0.4567\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 974.6216 - mean_absolute_error: 0.4651 - val_loss: 887.3851 - val_mean_absolute_error: 0.3338\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 813.9920 - mean_absolute_error: 0.4518 - val_loss: 739.6920 - val_mean_absolute_error: 0.3397\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 677.5780 - mean_absolute_error: 0.4532 - val_loss: 614.8801 - val_mean_absolute_error: 0.4289\n",
      "0.05555555555555555\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1402.2248 - mean_absolute_error: 3.8295 - val_loss: 1263.5319 - val_mean_absolute_error: 1.8311\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 1161.4503 - mean_absolute_error: 0.9072 - val_loss: 1059.3632 - val_mean_absolute_error: 0.6995\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 2ms/step - loss: 972.3897 - mean_absolute_error: 0.4836 - val_loss: 884.6924 - val_mean_absolute_error: 0.4768\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 810.6654 - mean_absolute_error: 0.4166 - val_loss: 736.1966 - val_mean_absolute_error: 0.4263\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 673.6505 - mean_absolute_error: 0.3860 - val_loss: 610.7846 - val_mean_absolute_error: 0.3570\n",
      "0.08333333333333333\n",
      "{'layer_number': 2, 'node_number': 20, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1405.0639 - mean_absolute_error: 4.2448 - val_loss: 1257.7892 - val_mean_absolute_error: 1.5026\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1155.8924 - mean_absolute_error: 0.8933 - val_loss: 1052.8207 - val_mean_absolute_error: 0.6722\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 965.3438 - mean_absolute_error: 0.4411 - val_loss: 877.1823 - val_mean_absolute_error: 0.3073\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 803.2020 - mean_absolute_error: 0.3691 - val_loss: 728.6304 - val_mean_absolute_error: 0.3203\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 666.3600 - mean_absolute_error: 0.3977 - val_loss: 603.6795 - val_mean_absolute_error: 0.3485\n",
      "0.1111111111111111\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 5s 5ms/step - loss: 1386.4150 - mean_absolute_error: 4.4281 - val_loss: 1238.1702 - val_mean_absolute_error: 4.6721\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1099.8068 - mean_absolute_error: 1.0072 - val_loss: 981.0547 - val_mean_absolute_error: 0.6117\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 882.9154 - mean_absolute_error: 0.4606 - val_loss: 785.2208 - val_mean_absolute_error: 0.4076\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 705.1469 - mean_absolute_error: 0.3765 - val_loss: 625.5779 - val_mean_absolute_error: 0.3502\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 560.7909 - mean_absolute_error: 0.3672 - val_loss: 496.5420 - val_mean_absolute_error: 0.3534\n",
      "0.1388888888888889\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 6s 6ms/step - loss: 1385.6957 - mean_absolute_error: 4.5124 - val_loss: 1220.3373 - val_mean_absolute_error: 2.8531\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1094.9688 - mean_absolute_error: 0.9978 - val_loss: 975.0447 - val_mean_absolute_error: 0.5766\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 876.6834 - mean_absolute_error: 0.5475 - val_loss: 778.4701 - val_mean_absolute_error: 0.3583\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 698.5683 - mean_absolute_error: 0.5065 - val_loss: 618.9614 - val_mean_absolute_error: 0.3703\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 554.4766 - mean_absolute_error: 0.4399 - val_loss: 490.4581 - val_mean_absolute_error: 0.3787\n",
      "0.16666666666666666\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 6s 6ms/step - loss: 1369.8562 - mean_absolute_error: 3.3377 - val_loss: 1223.0594 - val_mean_absolute_error: 3.4488\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1090.8489 - mean_absolute_error: 0.7158 - val_loss: 970.7902 - val_mean_absolute_error: 0.5057\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 872.0584 - mean_absolute_error: 0.4631 - val_loss: 774.1474 - val_mean_absolute_error: 0.5688\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 694.0136 - mean_absolute_error: 0.4350 - val_loss: 614.6684 - val_mean_absolute_error: 0.3533\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 550.6060 - mean_absolute_error: 0.4743 - val_loss: 487.1406 - val_mean_absolute_error: 0.5034\n",
      "0.19444444444444445\n",
      "{'layer_number': 2, 'node_number': 30, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 5s 5ms/step - loss: 1390.7690 - mean_absolute_error: 4.8446 - val_loss: 1241.0419 - val_mean_absolute_error: 5.0845\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1098.3321 - mean_absolute_error: 1.1136 - val_loss: 978.8710 - val_mean_absolute_error: 0.5553\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 880.7057 - mean_absolute_error: 0.4641 - val_loss: 782.7178 - val_mean_absolute_error: 0.2906\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 702.6849 - mean_absolute_error: 0.3931 - val_loss: 623.0443 - val_mean_absolute_error: 0.3542\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 558.2866 - mean_absolute_error: 0.4137 - val_loss: 494.0156 - val_mean_absolute_error: 0.3579\n",
      "0.2222222222222222\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 1334.2547 - mean_absolute_error: 2.9166 - val_loss: 1150.6787 - val_mean_absolute_error: 1.8090\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 1003.1897 - mean_absolute_error: 0.7427 - val_loss: 861.1611 - val_mean_absolute_error: 0.7661\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 747.8093 - mean_absolute_error: 0.6038 - val_loss: 637.7998 - val_mean_absolute_error: 0.6014\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 552.2794 - mean_absolute_error: 0.6376 - val_loss: 469.2468 - val_mean_absolute_error: 0.5808\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 405.7075 - mean_absolute_error: 0.6715 - val_loss: 344.3601 - val_mean_absolute_error: 0.8347\n",
      "0.25\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': True, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 1350.3110 - mean_absolute_error: 4.2632 - val_loss: 1161.2521 - val_mean_absolute_error: 3.6678\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 5s 4ms/step - loss: 1003.9733 - mean_absolute_error: 0.9930 - val_loss: 859.3328 - val_mean_absolute_error: 0.3749\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 6s 6ms/step - loss: 745.4239 - mean_absolute_error: 0.5112 - val_loss: 633.9540 - val_mean_absolute_error: 0.3760\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 6s 5ms/step - loss: 547.2525 - mean_absolute_error: 0.4468 - val_loss: 463.2423 - val_mean_absolute_error: 0.4519\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 6s 6ms/step - loss: 398.6610 - mean_absolute_error: 0.5386 - val_loss: 336.1077 - val_mean_absolute_error: 0.3969\n",
      "0.2777777777777778\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': False, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 10s 10ms/step - loss: 1307.0553 - mean_absolute_error: 1.3897 - val_loss: 1125.6975 - val_mean_absolute_error: 1.4815\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 974.6180 - mean_absolute_error: 0.7252 - val_loss: 830.5348 - val_mean_absolute_error: 0.7776\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 718.6367 - mean_absolute_error: 0.9067 - val_loss: 610.5605 - val_mean_absolute_error: 0.9616\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 530.4511 - mean_absolute_error: 1.2332 - val_loss: 453.1673 - val_mean_absolute_error: 1.5430\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 397.3025 - mean_absolute_error: 1.7388 - val_loss: 369.1255 - val_mean_absolute_error: 5.3613\n",
      "0.3055555555555556\n",
      "{'layer_number': 2, 'node_number': 60, 'resnet': False, 'dropout': 0.2}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 1354.8314 - mean_absolute_error: 4.9593 - val_loss: 1149.7634 - val_mean_absolute_error: 3.4575\n",
      "Epoch 2/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 992.5474 - mean_absolute_error: 1.1045 - val_loss: 846.0068 - val_mean_absolute_error: 0.4466\n",
      "Epoch 3/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 731.3587 - mean_absolute_error: 0.5064 - val_loss: 619.6874 - val_mean_absolute_error: 0.3889\n",
      "Epoch 4/5\n",
      "1024/1024 [==============================] - 4s 4ms/step - loss: 533.2692 - mean_absolute_error: 0.4748 - val_loss: 449.5864 - val_mean_absolute_error: 0.3364\n",
      "Epoch 5/5\n",
      "1024/1024 [==============================] - 5s 4ms/step - loss: 385.7820 - mean_absolute_error: 0.5111 - val_loss: 324.0622 - val_mean_absolute_error: 0.3696\n",
      "0.3333333333333333\n",
      "{'layer_number': 4, 'node_number': 20, 'resnet': True, 'dropout': 0.0}\n",
      "Train on 1024 samples, validate on 257 samples\n",
      "Epoch 1/5\n",
      "1024/1024 [==============================] - 7s 7ms/step - loss: 1432.8409 - mean_absolute_error: 5.7160 - val_loss: 1295.1445 - val_mean_absolute_error: 5.4716\n",
      "Epoch 2/5\n",
      "  64/1024 [>.............................] - ETA: 2s - loss: 1268.4061 - mean_absolute_error: 3.0596"
     ]
    }
   ],
   "source": [
    "best_params, model = predictor_resnet(X_train,y_train, X_test,y_test,params_matrix_resnetdense)\n",
    "store_best_param(PATH, response_dataframe.columns[j], 'resnet', best_params)\n",
    "store_prediction(model,y_test, X_test,'resnet', PATH,response_dataframe.columns[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth  min_samples_split  learning_rate loss\n",
       "0           100          2                  2           0.01   ls\n",
       "1           100          4                  2           0.01   ls\n",
       "2           200          2                  2           0.01   ls\n",
       "3           200          4                  2           0.01   ls"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "checkpoint_saver = CheckpointSaver(\"/Users/moradigd/Documents/Prediction/checkpoint.pkl\", compress=9)\n",
    "opt = BayesSearchCV( SVC(), { 'C': Real(1e-6, 1e+6, prior='log-uniform'), 'gamma': Real(1e-6, 1e+1, prior='log-uniform'), 'degree': Integer(1,8), 'kernel': Categorical(['linear', 'poly', 'rbf']), }, n_iter=32 )\n",
    "\n",
    "opt.fit(X_train, y_train,callback=[checkpoint_saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "\n",
    "In order to opmtimize the parameters, we first create a set of grid search parameters for the gradient boosted regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r_NoAB'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shap\n",
    "def exaplain_shap(model,X,y):\n",
    "    model.fit(X,y)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    return(shap_values)\n",
    "\n",
    "def save_model(model,PATH, tag):\n",
    "    from pickle import dump\n",
    "    dump(model, open(os.path.join(PATH, 'tuned_xgr_model_'+tag+'.txt'), 'wb'))\n",
    "\n",
    "def load_model(PATH, tag): \n",
    "    from pickle import load\n",
    "    return(load(open(os.path.join(PATH, 'tuned_xgr_model_'+tag+'.txt'), 'rb')))\n",
    "\n",
    "PATH=\"/Users/moradigd/Documents/Prediction/\"\n",
    "\n",
    "response='Metadata_median_NoAB.txt'\n",
    "features='pangene.txt'\n",
    "response_dataframe=pd.read_csv(os.path.join(PATH, response), index_col=0, sep=\"\\t\")\n",
    "response_dataframe.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "j=1\n",
    "best_params=pd.read_csv(os.path.join(PATH, \"best_params_gbregressor_\"+response_dataframe.columns[j]+\"_xgr.txt\"), index_col=0, sep=\"\\t\")\n",
    "best_model=ensemble.GradientBoostingRegressor(**best_params.to_dict('records')[0])\n",
    "\n",
    "X_test=pd.read_csv(os.path.join(PATH, 'X_test_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "y_test=pd.read_csv(os.path.join(PATH, 'y_test_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "\n",
    "X_train=pd.read_csv(os.path.join(PATH, 'X_train_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "y_train=pd.read_csv(os.path.join(PATH, 'y_train_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "\n",
    "best_model.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "save_model(best_model,PATH, response_dataframe.columns[j])\n",
    "shap_results=exaplain_shap(load_model(PATH, response_dataframe.columns[j]),X_test,y_test)\n",
    "\n",
    "shap_max=pd.DataFrame(shap_results, columns=X_test.columns.values).max()\n",
    "shap_max=shap_max[shap_max != 0].sort_values(na_position='first')\n",
    "shap_max.index.name='Gene'\n",
    "shap_max = shap_max.reset_index(name='SHAP')\n",
    "shap_max.to_csv(os.path.join(PATH, 'new_shap_'+response_dataframe.columns[j]+'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'r_NoAB'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.summary_plot(shap_results, X_test)\n",
    "response_dataframe.columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Trees importance metrics\n",
    "\n",
    "In order to opmtimize the parameters, we first create a set of grid search parameters for the gradient boosted regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moradigd/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "best_params=pd.read_csv(os.path.join(PATH, \"best_params_gbregressor_\"+response_dataframe.columns[j]+\"_xgr.txt\"), index_col=0, sep=\"\\t\")\n",
    "best_model=ensemble.GradientBoostingRegressor(**best_params.to_dict('records')[0])\n",
    "\n",
    "X_test=pd.read_csv(os.path.join(PATH, 'X_test_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "y_test=pd.read_csv(os.path.join(PATH, 'y_test_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "\n",
    "X_train=pd.read_csv(os.path.join(PATH, 'X_train_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "y_train=pd.read_csv(os.path.join(PATH, 'y_train_'+response_dataframe.columns[j]+'.txt'), sep=\"\\t\", index_col=0)\n",
    "\n",
    "best_model.fit(X_train,y_train)\n",
    "save_model(best_model,PATH, response_dataframe.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "0.45\n",
      "0.5\n",
      "0.55\n",
      "0.6\n",
      "0.65\n",
      "0.7\n",
      "0.75\n",
      "0.8\n",
      "0.85\n",
      "0.9\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "def feature_gbr_importance(X_test,y_test, feature_name, iteration,PATH):\n",
    "    output_feature_importance_agg=pd.DataFrame()\n",
    "    for i in range(iteration):\n",
    "        print(i/iteration)\n",
    "        feature_names=np.array(X_test.columns.values)\n",
    "        #model = load_model(PATH, response_dataframe.columns[0])\n",
    "        model = load_model(PATH, feature_name)\n",
    "        model.fit(X_test,np.ravel(y_test))\n",
    "        importance=model.feature_importances_\n",
    "    \n",
    "        output_feature_importance=pd.DataFrame({'Gene':feature_names,'Importance':importance})\n",
    "        output_feature_importance=output_feature_importance[output_feature_importance.Importance>0].sort_values(by=['Importance'], ascending=False)\n",
    "        output_feature_importance['rank']=np.arange(output_feature_importance.shape[0])+1\n",
    "        output_feature_importance_agg=output_feature_importance_agg.append(output_feature_importance, ignore_index = True)\n",
    "\n",
    "    counts = output_feature_importance_agg.Gene.value_counts().to_dict()\n",
    "    output_feature_importance_agg=output_feature_importance_agg.groupby(['Gene']).mean()\n",
    "    output_feature_importance_agg['frequency']=[counts[i] for i in output_feature_importance_agg.index.tolist()]\n",
    "    return(output_feature_importance_agg)\n",
    "\n",
    "output=feature_gbr_importance(X_test,y_test,  response_dataframe.columns[j], 20,PATH)\n",
    "output.to_csv(os.path.join(PATH,\"importance_xgr_\"+response_dataframe.columns[j]+\".txt\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/Users/moradigd/Documents/Prediction/\"\n",
    "\n",
    "response='Metadata_median_NoAB.txt'\n",
    "features='pangene.txt'\n",
    "\n",
    "gene='wcaE'\n",
    "j=1\n",
    "pangenome_dataframe=pd.read_csv(os.path.join(PATH, features), index_col=0, sep=\"\\t\")\n",
    "reponse_dataframe=pd.read_csv(os.path.join(PATH, response), index_col=0, sep=\"\\t\")\n",
    "response_dataframe.columns[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4- Annotation\n",
    "\n",
    "\n",
    "### GFF manipulation \n",
    "The class extract the proteome from the gff file. The extracted proteome will then be used as a database for pblast.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "class GFF:\n",
    "    def __init__(self,PATH):\n",
    "        self.PATH=PATH\n",
    "            \n",
    "    def reverse_complement(self, seq): \n",
    "        '''\n",
    "        input: DNA sequence\n",
    "        output: reverse complement\n",
    "        '''\n",
    "        revcompl = lambda x: ''.join([{'A':'T','C':'G','G':'C','T':'A', 'N':'N'}[B] for B in x][::-1])\n",
    "        return(revcompl(seq))\n",
    "\n",
    "    def translate(self, seq): \n",
    "        '''\n",
    "        input: DNA sequence\n",
    "        output: prontein translation\n",
    "        '''\n",
    "        table = { \n",
    "            'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M', \n",
    "            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T', \n",
    "            'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K', \n",
    "            'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',                  \n",
    "            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L', \n",
    "            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P', \n",
    "            'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q', \n",
    "            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R', \n",
    "            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V', \n",
    "            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A', \n",
    "            'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E', \n",
    "            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G', \n",
    "            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S', \n",
    "            'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L', \n",
    "            'TAC':'Y', 'TAT':'Y', 'TAA':'_', 'TAG':'_', \n",
    "            'TGC':'C', 'TGT':'C', 'TGA':'_', 'TGG':'W', \n",
    "        } \n",
    "        protein =\"\" \n",
    "        for i in range(0, len(seq), 3): \n",
    "            codon = seq[i:i + 3] \n",
    "            protein+= table.get(codon, \"X\") \n",
    "        return protein \n",
    "\n",
    "    def extract_gene(self,line_tmp, gff_lines):\n",
    "        '''\n",
    "        line_tmp: the line number in the gff file \n",
    "        gff_line: list of lines in the gff file\n",
    "        output: gene sequence\n",
    "        '''\n",
    "        import re\n",
    "        features=line_tmp.split('\\t')\n",
    "        contig_line=[i for i,x in enumerate(gff_lines) if '>'+features[0]+'\\n' in x][0]+1\n",
    "        start_line=int(features[3])//60+contig_line\n",
    "        end_line=int(features[4])//60+contig_line\n",
    "        begin=gff_lines[start_line][int(features[3])%60-1:60]\n",
    "\n",
    "        intermediate=[]\n",
    "        if end_line>(start_line+1):\n",
    "            intermediate=gff_lines[start_line+1:end_line]\n",
    "            intermediate=[re.sub('\\n', '', i) for i in intermediate]\n",
    "\n",
    "        end=gff_lines[end_line][0:int(features[4])%60]\n",
    "        gene=''.join([begin]+intermediate+[end])\n",
    "    \n",
    "        if features[6]=='-':\n",
    "            gene=self.reverse_complement(gene)\n",
    "    \n",
    "        return(gene)\n",
    "    \n",
    "    def gff_to_fasta(self,gff_file):\n",
    "        '''\n",
    "        converts gff file to fasta\n",
    "        '''\n",
    "        import os\n",
    "        import re\n",
    "\n",
    "        annotation_file=os.path.join(self.PATH,gff_file)\n",
    "        holder=[]\n",
    "        with open(annotation_file,'r') as file:\n",
    "            gff_lines = file.readlines()\n",
    "    \n",
    "            ids=[i for i in range(len(gff_lines)) if \"##FASTA\" in gff_lines[i]]\n",
    "            holder=gff_lines[ids[0]+1:len(gff_lines)]\n",
    "    \n",
    "        with open(os.path.join(self.PATH,re.sub(r'.velvet.gff',r'',gff_file)+\".fasta\"), 'w') as file:\n",
    "            for item in holder:\n",
    "                file.write(\"%s\" % item)\n",
    "            \n",
    "    def store_profile(self,profile, file_name=\"profile.txt\"):\n",
    "        with open(os.path.join(self.PATH,file_name), 'w') as file:\n",
    "            for item in profile:\n",
    "                file.write(\"%s\\n\" % item)\n",
    "                \n",
    "    def extract_proteome(self, gff_file):\n",
    "        '''\n",
    "        gff_file: the name of the gff file \n",
    "        PATH: the path to the file\n",
    "    \n",
    "        output: extracted proteome of the genes with proteome suffix stored in PATH\n",
    "        '''\n",
    "        import pyprog\n",
    "        from time import sleep\n",
    "    \n",
    "        annotation_file=os.path.join(self.PATH,gff_file)\n",
    "        with open(annotation_file,'r') as file:\n",
    "            gff_lines = file.readlines()\n",
    "            line_tmp=[i for i in gff_lines if 'CDS' in i]\n",
    "            profile=[]\n",
    "            \n",
    "            print(\"Extract Proteome\")\n",
    "            \n",
    "            prog = pyprog.ProgressBar(\" \", \" \", total=len(line_tmp), bar_length=50, complete_symbol=\"=\", not_complete_symbol=\" \", wrap_bar_prefix=\" [\", wrap_bar_suffix=\"] \", progress_explain=\"\", progress_loc=pyprog.ProgressBar.PROGRESS_LOC_END)\n",
    "            prog.update()\n",
    "\n",
    "            for j in range(len(line_tmp)):\n",
    "\n",
    "                sleep(0.1)\n",
    "                prog.set_stat(j + 1)\n",
    "                prog.update()\n",
    "\n",
    "                header='>Gene'+str(j)\n",
    "                protein=self.translate(self.extract_gene(line_tmp[j], gff_lines))\n",
    "\n",
    "                profile.append(header)\n",
    "                profile.append(protein)\n",
    "\n",
    "            prog.end()\n",
    "        \n",
    "        self.store_profile(profile, 'proteome_'+gff_file)\n",
    "                \n",
    "    def profile_pangenome_constructor(self,genes_list):\n",
    "        pangenome_file=os.path.join(self.PATH,'gene_presence_absence.csv')\n",
    "        pangenome=pd.read_csv(pangenome_file, index_col=0)    \n",
    "        return(pangenome.loc[genes_list,:])\n",
    "\n",
    "    def protein_extractor(self, genes_info, dna=False):\n",
    "        gene_id=genes_info.iloc[0].split('\\t')[0]\n",
    "        genome=genes_info.index[0]\n",
    "    \n",
    "        annotation_file=os.path.join(self.PATH,genome+'.velvet.gff')\n",
    "        with open(annotation_file,'r') as file:\n",
    "            gff_lines = file.readlines()\n",
    "            line_tmp=[i for i in gff_lines if 'CDS' in i and gene_id in i]\n",
    "            if len(line_tmp)>0:\n",
    "                header='>'+genes_info.name\n",
    "                if dna==False:\n",
    "                    protein=self.translate(self.extract_gene(line_tmp[0], gff_lines))\n",
    "                else:\n",
    "                    protein=self.extract_gene(line_tmp[0], gff_lines)\n",
    "                return([header,protein])\n",
    "\n",
    "    def profile_constructor(self, pangenome, profile_file_name=\"profile.txt\", dna=False):\n",
    "        profile=[]\n",
    "        for i in range(pangenome.shape[0]):\n",
    "            genes_info=pangenome.iloc[i,13:pangenome.shape[1]]\n",
    "            genes_info.dropna(inplace=True)\n",
    "            gene_id=genes_info.iloc[0].split('\\t')[0]\n",
    "            tmp=self.protein_extractor(genes_info, dna)\n",
    "            profile.append(tmp[0])\n",
    "            profile.append(tmp[1])\n",
    "        self.store_profile(profile, profile_file_name)\n",
    "        return(profile)\n",
    "    \n",
    "    def report_profile(self,genes_list, gff_file,cutoff=95):\n",
    "        blastp_results=pd.read_csv(os.path.join(self.PATH,'blastp_proteome_'+gff_file+'.out'),header=None,sep=\"\\t\")\n",
    "        blastp_results_filtered=blastp_results[(blastp_results.iloc[:,2] >cutoff)]\n",
    "        output=pd.DataFrame(np.zeros(len(genes_list)), index=genes_list, columns=[gff_file])\n",
    "        output.loc[blastp_results_filtered.iloc[:,0].values]=1\n",
    "        return(output)\n",
    "\n",
    "\n",
    "    def make_blast_database(self,gff_file, prefix=\"proteome_\", database=\"prot\"):\n",
    "        '''\n",
    "        PATH: directory the file\n",
    "        gff_file: the input gff file \n",
    "        output: the blast data set\n",
    "        '''\n",
    "        import os\n",
    "        search=prefix+gff_file\n",
    "        os.system('makeblastdb -dbtype '+database+' -in '+self.PATH+'/'+search)\n",
    "    \n",
    "    def run_blastp(self,gff_file, query, postfix=''):\n",
    "        '''\n",
    "        PATH: directory of input and output files \n",
    "        gff_file: the name of the gff file\n",
    "        output: the blast output of the file\n",
    "        '''\n",
    "        import os\n",
    "        os.system('blastp -db '+self.PATH+'/'+'proteome_'+gff_file+' -query '+self.PATH+'/'+query+' -outfmt 6 '+'-out '+self.PATH+'/'+'blastp_proteome'+gff_file+postfix+'.out')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Proteome\n",
      "  [==================================================] 100% \n"
     ]
    }
   ],
   "source": [
    "PATH='/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome/jpiamr/subsample'\n",
    "gff_file='26329_1#221.velvet.gff'\n",
    "GFF(PATH).extract_proteome(gff_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "18\n",
      "31\n",
      "33\n",
      "43\n",
      "48\n",
      "50\n",
      "64\n",
      "66\n",
      "68\n",
      "83\n",
      "84\n",
      "85\n",
      "88\n",
      "107\n",
      "108\n",
      "110\n",
      "114\n",
      "121\n",
      "122\n",
      "125\n",
      "134\n",
      "135\n",
      "137\n",
      "138\n",
      "139\n",
      "144\n",
      "146\n",
      "147\n",
      "149\n",
      "153\n",
      "162\n",
      "178\n",
      "188\n",
      "196\n",
      "199\n",
      "203\n",
      "205\n",
      "207\n",
      "209\n",
      "230\n",
      "233\n",
      "234\n",
      "243\n",
      "244\n",
      "251\n",
      "254\n",
      "260\n",
      "261\n",
      "271\n",
      "281\n",
      "285\n",
      "287\n",
      "291\n",
      "293\n",
      "295\n",
      "306\n",
      "314\n",
      "317\n",
      "324\n",
      "326\n",
      "331\n",
      "333\n",
      "342\n",
      "351\n",
      "352\n",
      "354\n",
      "371\n",
      "377\n",
      "385\n",
      "388\n",
      "390\n",
      "393\n",
      "395\n",
      "409\n",
      "412\n",
      "417\n",
      "422\n",
      "428\n",
      "433\n",
      "441\n",
      "449\n",
      "453\n",
      "457\n",
      "458\n",
      "459\n",
      "471\n",
      "475\n",
      "476\n",
      "489\n",
      "495\n",
      "496\n",
      "498\n",
      "503\n",
      "504\n",
      "507\n",
      "510\n",
      "512\n",
      "520\n",
      "524\n",
      "528\n",
      "534\n",
      "536\n",
      "548\n",
      "549\n",
      "552\n",
      "554\n",
      "560\n",
      "561\n",
      "565\n",
      "567\n",
      "568\n",
      "571\n",
      "579\n",
      "589\n",
      "596\n",
      "604\n",
      "607\n",
      "609\n",
      "611\n",
      "614\n",
      "616\n",
      "619\n",
      "621\n",
      "622\n",
      "624\n",
      "628\n",
      "631\n",
      "633\n",
      "634\n",
      "639\n",
      "641\n",
      "642\n",
      "647\n",
      "652\n",
      "654\n",
      "656\n",
      "693\n",
      "696\n",
      "698\n",
      "704\n",
      "712\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "724\n",
      "725\n",
      "726\n",
      "732\n",
      "743\n",
      "746\n",
      "750\n",
      "755\n",
      "758\n",
      "760\n",
      "763\n",
      "770\n",
      "772\n",
      "773\n",
      "779\n",
      "783\n",
      "786\n",
      "795\n",
      "801\n",
      "810\n",
      "819\n",
      "824\n",
      "831\n",
      "832\n",
      "840\n",
      "850\n",
      "851\n",
      "858\n",
      "859\n",
      "876\n",
      "877\n",
      "883\n",
      "886\n",
      "889\n",
      "890\n",
      "893\n",
      "895\n",
      "911\n",
      "914\n",
      "915\n",
      "917\n",
      "923\n",
      "927\n",
      "932\n",
      "939\n",
      "940\n",
      "945\n",
      "950\n",
      "963\n",
      "964\n",
      "977\n",
      "983\n",
      "993\n",
      "997\n",
      "1001\n",
      "1009\n",
      "1013\n",
      "1021\n",
      "1023\n",
      "1030\n",
      "1032\n",
      "1033\n",
      "1039\n",
      "1049\n",
      "1051\n",
      "1054\n",
      "1059\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1098\n",
      "1101\n",
      "1105\n",
      "1120\n",
      "1123\n",
      "1129\n",
      "1130\n",
      "1134\n",
      "1138\n",
      "1143\n",
      "1146\n",
      "1156\n",
      "1158\n",
      "1160\n",
      "1167\n",
      "1177\n",
      "1181\n",
      "1182\n",
      "1189\n",
      "1194\n",
      "1197\n",
      "1198\n",
      "1206\n",
      "1208\n",
      "1219\n",
      "1223\n",
      "1247\n",
      "1264\n",
      "1268\n",
      "1271\n",
      "1272\n",
      "1285\n",
      "1286\n",
      "1292\n",
      "1296\n",
      "1302\n",
      "1313\n",
      "1320\n",
      "1328\n",
      "1329\n",
      "1334\n",
      "1337\n",
      "1349\n",
      "1356\n",
      "1359\n",
      "1376\n",
      "1380\n",
      "1382\n",
      "1383\n",
      "1386\n",
      "1406\n",
      "1411\n",
      "1417\n",
      "1420\n",
      "1421\n",
      "1430\n",
      "1431\n",
      "1447\n",
      "1448\n",
      "1450\n",
      "1452\n",
      "1455\n",
      "1481\n",
      "1498\n",
      "1502\n",
      "1503\n",
      "1505\n",
      "1516\n",
      "1520\n",
      "1531\n",
      "1539\n",
      "1540\n",
      "1542\n",
      "1548\n",
      "1556\n",
      "1562\n",
      "1563\n",
      "1565\n",
      "1568\n",
      "1572\n",
      "1573\n",
      "1577\n",
      "1580\n",
      "1582\n",
      "1588\n",
      "1592\n",
      "1613\n",
      "1615\n",
      "1616\n",
      "1619\n",
      "1629\n",
      "1630\n",
      "1636\n",
      "1644\n",
      "1646\n",
      "1650\n",
      "1653\n",
      "1655\n",
      "1659\n",
      "1662\n",
      "1666\n",
      "1668\n",
      "1671\n",
      "1673\n",
      "1682\n",
      "1686\n",
      "1687\n",
      "1689\n",
      "1691\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1707\n",
      "1710\n",
      "1711\n",
      "1713\n",
      "1723\n",
      "1729\n",
      "1741\n",
      "1743\n",
      "1752\n",
      "1766\n",
      "1767\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1784\n",
      "1790\n",
      "1791\n",
      "1803\n",
      "1804\n",
      "1808\n",
      "1813\n",
      "1816\n",
      "1818\n",
      "1822\n",
      "1824\n",
      "1840\n",
      "1847\n",
      "1848\n",
      "1855\n",
      "1857\n",
      "1861\n",
      "1862\n",
      "1865\n"
     ]
    }
   ],
   "source": [
    "#extract genes\n",
    "PATH='/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome'\n",
    "#gff_file='26329_1#221.velvet.gff'\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_list=[re.sub(PATH+\"/\",r'',i) for i in glob.glob(PATH+\"/out_2*.fasta\")]\n",
    "tags=[re.sub('out_','', i) for i in file_list]\n",
    "tags=[re.sub('.fasta','', i) for i in tags]\n",
    "gene_presence_absence=pd.DataFrame(np.zeros([len(file_list),len(genes_list)]), columns=genes_list, index=tags)\n",
    "\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    if os.path.getsize(os.path.join(PATH,file_list[i])) > 0:\n",
    "        print(i)\n",
    "        tmp=pd.read_csv(os.path.join(PATH,file_list[i]), sep=\"\\t\", header=None)\n",
    "        gene_presence_absence.loc[tags[i],tmp.iloc[:,1].values]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>group_55440',\n",
       " 'GTGAGTGGTTGCGTGATTCCGCCGAATGATAGCCAGGCGCTGGTGGAGGCGATGAATGAGCTCTGGAATAACGAGGAAACCTCCAACCGCTATGGCGAAAACTCGCGTCGTCGTTTTGAAGAGATGTTTACTGCCGACCATATGATTGACGCCTATGTCAATCTCTACACTACATTGCTGGAAAGTAAATCCTGA',\n",
       " '>kpsD_1',\n",
       " 'ATGAAGAAAAAAATTGTTAGATTTTCGGCATTAGCATTGGCAATTGGGTTTTTATCGGGTTGTACCATTATCCCTGGTCAGGGATTAAATAGTCTGCGGAAGAACGTAGTTGAGCTTCCGGACAGCGACTACGATCTGGATAAACTGGTCAATGTGTACCCGATGACGCCGGGTCTGATCGACCAACTCCGTCCGGAGACTATACTCGCTCGTCCAAACCCGCAGCTTGATAATTTATTGCGCAGTTATGAATATCGCATCGGTGTAGGCGATGTACTGATGGTCACTGTTTGGGATCACCCAGAGTTGACTACACCTGCAGGCCAATACCGTAGCGCAAGTGATACCGGTAACTGGGTTAATTCAGATGGTACTATTTTCTATCCTTATATTGGTAAGGTGCAGGTAGCAGGGAAAACTCTCGCTCAGGTAAGACAGGATATAGCCAGCCGACTGACCACTTATATTGAAAGCCCTCAGGTAGATGTAAGTGTCGCAGCGTTTCGTTCGCAAAAAGCGTATGTGACAGGTGAAGTTACTAAATCGGGACAGCAACCAATTACTAATATTCCATTAACGGTGATGGATGCCATTAATGCGGCTGGTGGGCTTGCTCCAGATGCTGATTGGCGAAATGTTGTATTAACTCATAACGGAAAAGACATAAAAGTCTCACTATATGCATTAATGCAGAAAGGGGATTTGACCCAAAATCACCTGTTATATCCAGGCGATATTCTTTTTGTGCCGCGTAATGACGATCTAAAAGTATTTGTCATGGGCGAAGTAGGTAAGCAAAGCACAATGAAGATGGATAGAAGTGGGATGACATTGGCGGAAGCTCTGGGTAATGCTGAAGGTATGTCACAAGCTTTCAGTGACGCCACTGGTGTGTTTGTCATTCGTCAGATTAAAGGTGATAGTCAGGGTAAAATTGCTAATATCTATCAACTTAATGCTCAGGATGCCTCGGCTATGGTGTTAGGTACTGAATTCCAGTTACAGCCGTATGATATTGTTTATGTCACTACAGCACCATTGGTTCGCTGGAATCGCGTGATTTCTCAACTGGTTCCAACAATTTCGGGTGTACATGATATGACAGAAACAACCCGTTATATTAAGGACTGGCCATAA',\n",
       " '>group_51316',\n",
       " 'ATGATAAAAATTGCGCGCATTGCCGTGACATTGGGCTTGCTTTCCTCACTGGGAGCCCAGGCTTACGCGGCCGGGTTAGTAGTAAATGATAACGATCTGCGAAACGACCTTGCCTGGCTTTCCGATCGTGGGGTCATCCATCTAAGCCTGTCGACCTGGCCGCTGAGCCAGGAAGAGATCGCCCGGGCACTAAAAAAGGCCAAACCATCCTATTCTTCTGAGCAAGTGGTGCTGGCCCGTATCAACCAGCGACTGTCTGCTTTAAAAGCCGATTTCCGGGTCACCGGCTACACCTCGACCGACCAGCCGGGCACCCCGCAGGGGTTTGGTCAGACGCAGCCGGCGGATAACTCCTTAGGCCTGGCGTTTAACAACAGCGGCGAGTGGTGGGATGTCCACCTTCAGGGTAACGTCGAAGGGGGGGAGCGGATCAGCAACGGATCGCGCTTCAACGCCAACGGCGCCTACGGCGCGGTGAAGTTCTGGAACCAGTGGCTCTCTTTTGGTCAGGTTCCGCAGTGGTGGGGACCGGGCTATGAAGGAAGCCTGATCCGCGGGGATGCGATGCGACCGATGACCGGTTTCCTGATGCAGCGAGCCGAGCAGGCGGCGCCGGAAACCTGGTGGCTGCGCTGGGTGGGTCCATGGCAGTACCAGATCTCTGCCAGCCAGATGAATCAGTACACCGCTGTGCCCCATGCTAAAATTATTGGTGGTCGTTTCACCTTCACGCCGTTCCAGTCTTTAGAATTAGGCGCGTCGCGCATTATGCAGTGGGGCGGGGAAGGTCGACCGCAATCATTCAGCAGTTTCTGGGATGGCTTCACTGGCCATGATAATACCGGGACAGATAACGAACCGGGTAACCAGCTGGCAGGGTTTGACTTTAAGTTCAAACTTGAACCAACCCTTGGCTGGCCAGTGAGTTTCTATGGGCAGATGGTTGGTGAGGATGAGTCTGGTTACCTACCATCTGCGAATATGTTTCTTGGCGGGGTTGAAGGACACCACGGCTGGGGTAAGGATGCGGTTAACTGGTATGTGGAAGCGCATGATACACGTACCAATATGAGCCGGACCAATTACAGCTATACCCACCACATCTACAAAGATGGTTATTACCAACAAGGGTATCCACTGGGCGATGCGATGGGCGGAGATGGTCAACTTATTGCTGGTAAAGTTGAGCTTATTACCGAAGATAACCAACGCTGGAGCACGCGCCTGGTGTACGCCAAAGTTAACCCGGAGAACCAGTCTATTAATAAAGCGTTCCCTCATGCTGATACCCTCAAGGGTTTACAGCTTGGCTGGAGCGGAGATGTTTATCAGTCGGTCCGCTTGAATACTTCACTGTGGTACACCAACGCGAACAACAGCGACAGCGATGACGTTGGGGCCAGTGCAGGGATAGAAATACCGTTTAGTTTATAA',\n",
       " '>group_47241',\n",
       " 'ATGCTCTATCTGATTGAGGACAACGAGTACAGTCGAAGAGCCATCGGCAAGTATATTGATGTCTGGCATTATCCTGACGGACATAAGGAGCTGCGACTAAATGGCGTGCTGCTGCCCTACTCCACCTATGACCGGCTTTCTGAGGTTGATCCCGTCGCCATTGTAGATAACAAGAGACTTGGCCATGTGTTGGATGTTGCCCGTCAGGTCCAGAGAAAACGGGACAATAATCGCTCACAATCGTTACCTTGTTCTGGTGATGAGCCTTCCCGCAGACGGCACGCCCCTAGCATCAACAAATCTCAGCGCTCACTGAACGAAGATGACCTACTTGAAGCCATGATAAAGCTTCAGGGAAGCTCTGAGGCCATCTTTGGTAAAAGGTGA']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome'\n",
    "genes_list=['group_55440','kpsD_1','group_51316','group_47241']\n",
    "tmp=GFF(PATH).profile_pangenome_constructor(genes_list)\n",
    "GFF(PATH).profile_constructor(tmp, dna=True)\n",
    "\n",
    "tmp=GFF(PATH).profile_pangenome_constructor(genes_list)\n",
    "tmp_f=GFF(PATH).profile_constructor(tmp, dna=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GFF(PATH).make_blast_database(\"profile.txt\",prefix=\"\", database=\"nucl\")\n",
    "#for i in *.fasta ; do echo $i; blastn -db profile.txt -query ${i} -outfmt 6 -out out_${i} ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26329_1#221.velvet.gff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sspB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iaaA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gyrA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>menH</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tktA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>visC</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bolA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>amtB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ytfT</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      26329_1#221.velvet.gff\n",
       "sspB                     1.0\n",
       "iaaA                     1.0\n",
       "gyrA                     1.0\n",
       "menH                     1.0\n",
       "tktA                     1.0\n",
       "visC                     1.0\n",
       "bolA                     1.0\n",
       "amtB                     1.0\n",
       "ytfT                     1.0"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome'\n",
    "GFF(PATH).report_profile(genes_list, gff_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH=\"/Users/moradigd/Documents/Prediction/\"\n",
    "\n",
    "response='Metadata_median_NoAB.txt'\n",
    "reponse_dataframe=pd.read_csv(os.path.join(PATH, response), index_col=0, sep=\"\\t\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "gene_presence_absence.join(reponse_dataframe,how='inner').loc[:,['y_NoAB','kpsD_1']].boxplot(by=['kpsD_1'])\n",
    "plt.show()\n",
    "#reponse_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplication and annotation \n",
    "\n",
    "\n",
    "The list of significant is further processed to attach functioinal groups and duplicate the entries with an identical gene presence-absence pattern. The following class process the final class. It takes the postfix of the drug class and returns the complete annotation file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hits:\n",
    "    def __init__(self, PATH):\n",
    "        self.PATH=PATH\n",
    "        \n",
    "    def create_pattern(self, pangenome_Rtab='gene_presence_absence.Rtab'):\n",
    "        import pandas as pd\n",
    "        import os\n",
    "    \n",
    "        pangenome_Rtab_file=pd.read_csv(os.path.join(self.PATH, pangenome_Rtab), index_col=0, sep='\\t')\n",
    "        pattern=pangenome_Rtab_file.apply(lambda x: str(x.tolist()), axis=1)\n",
    "        pattern_id=pd.DataFrame(list(zip(pangenome_Rtab_file.index.tolist(),pattern)))\n",
    "        pattern_id.columns=['Gene', 'Pattern']\n",
    "        pattern_id=pattern_id.set_index('Gene')\n",
    "    \n",
    "        return pattern_id\n",
    "\n",
    "    def define_importance(self, postfix, pattern=True):\n",
    "        import pandas as pd\n",
    "        import os\n",
    "    \n",
    "        postfix_importance='importance_xgr_'+postfix+'.txt'\n",
    "        importance=pd.read_csv(os.path.join(self.PATH, postfix_importance),  sep='\\t')\n",
    "        importance['Pattern']=self.pattern_id.Pattern[importance.Gene].tolist()\n",
    "        importance.drop('Gene', axis=1, inplace=True)\n",
    "        self.pattern_id=self.pattern_id.reset_index()\n",
    "        merged_pattern_importance = importance.merge(self.pattern_id, left_on=['Pattern'], right_on = ['Pattern'], how='left')\n",
    "        merged_pattern_importance.drop(['Pattern'], axis=1, inplace=pattern)\n",
    "        return merged_pattern_importance\n",
    "\n",
    "    def attach_annotation(self, pangenome_csv='gene_presence_absence.csv'):\n",
    "        pangenome_csv=pd.read_csv(os.path.join(self.PATH, pangenome_csv), index_col=0)\n",
    "        pangenome_csv=pangenome_csv.iloc[:,0:13]\n",
    "        return self.merged_pattern_importance.merge(pangenome_csv, left_on=['Gene'], right_on = ['Gene'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/Users/moradigd/Documents/Prediction/Pan_genome'\n",
    "Hits(PATH).create_pattern()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach COG code and category \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_file=\"/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome/26329_1#286.velvet.gff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_attribute_finder(locus, gff_file):\n",
    "    cog=open(gff_file)\n",
    "    lines_cog=cog.readlines()\n",
    "    indetified_line=lines_cog[np.where([locus in line for line in lines_cog])[0][0]]\n",
    "    annotation_field=indetified_line.split(\"\\t\")[8]\n",
    "    annotation_field_split=annotation_field.split(\";\")\n",
    "    return(annotation_field_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_finder(*annotation_field_split):\n",
    "    try:\n",
    "        annotation_field_split_product=annotation_field_split[np.where([\"product=\" in line for line in annotation_field_split])[0][0]]\n",
    "        return(re.sub(\"product=\", \"\", annotation_field_split_product))\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cog_finder(*annotation_field_split):\n",
    "    try:\n",
    "        COG_field=annotation_field_split[np.where([\"COG\" in line for line in annotation_field_split])[0][0]]\n",
    "        COG_field_split=COG_field.split(\",\")\n",
    "        COG_field_split_field=COG_field_split[np.where([\"COG\" in line for line in COG_field_split])[0][0]]\n",
    "        return(re.sub(\"protein motif:Cdd:\", \"\", COG_field_split_field))\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(output_dict, PATH,file_name=\"cog_info.json\"):\n",
    "    import json\n",
    "    import os\n",
    "    file=os.path.join(PATH, file_name)\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_dict,f,ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome/cog_info.json\"\n",
    "\n",
    "def read_json(file_name,PATH,data_frame=True):\n",
    "    with open(json_file_path, 'r') as j:\n",
    "        contents = json.loads(j.read())\n",
    "        if data_frame==True:\n",
    "            return(pd.DataFrame.from_dict(contents, orient='index'))\n",
    "        else:\n",
    "            return(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_genome_file=\"/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome/gene_presence_absence.csv\"\n",
    "pan_genome=pd.read_csv(pan_genome_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                                                                    ] 100%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-b1a57a1f9872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[%-100s] %d%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpan_genome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpan_genome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpan_genome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "PATH=\"/Users/moradigd/Desktop/test_pan/assemblies/gffs/pan_genome\"\n",
    "output={}\n",
    "for i in range(pan_genome.shape[0]):\n",
    "    \n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(\"[%-100s] %d%%\" % ('='*int(100*i/pan_genome.shape[0]), 100))\n",
    "    sys.stdout.flush()\n",
    "    sleep(0.25)\n",
    "    \n",
    "    tmp=pan_genome.iloc[i,14:pan_genome.shape[1]].dropna().tolist()\n",
    "    locus=tmp[0].split(\"\\t\")[0]\n",
    "    gff_file=os.path.join(PATH,\"_\".join(locus.split(\"_\")[0:2])+\".velvet.gff\")\n",
    "    annotation_field_split=gene_attribute_finder(locus,gff_file)\n",
    "    COG=cog_finder(*annotation_field_split)\n",
    "    product=product_finder(*annotation_field_split)\n",
    "    if COG!=None:\n",
    "        output[pan_genome.iloc[i,0]]={'COG': COG, 'product': product}\n",
    "    elif COG==None:\n",
    "        output[pan_genome.iloc[i,0]]={'product': product}\n",
    "\n",
    "write_json(output, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(output, PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
